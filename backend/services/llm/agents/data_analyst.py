"""
æ•°æ®åˆ†æå¸ˆAgent - èµµä¸½å¨…
è´Ÿè´£æ•°æ®æå–ã€åˆ†æå’Œå¯è§†åŒ–
"""
import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List
import re # Added for regex in _execute_specific_task

from metagpt.actions import Action
from metagpt.schema import Message
from metagpt.logs import logger

from .base import BaseAgent
from backend.services.llm_provider import llm


class DataExtractionAction(Action):
    """æ•°æ®æå–åŠ¨ä½œ"""
    
    async def run(self, content: str, data_type: str = "æ•°å€¼æ•°æ®") -> str:
        """ä»å†…å®¹ä¸­æå–æ•°æ®"""
        prompt = f"""
ä½ æ˜¯æ•°æ®åˆ†æå¸ˆèµµä¸½å¨…ï¼Œè¯·ä»ä»¥ä¸‹å†…å®¹ä¸­æå–{data_type}ï¼š

å†…å®¹ï¼š
{content}

è¯·æå–æ‰€æœ‰ç›¸å…³çš„æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
1. æ•°å€¼æ•°æ®ï¼ˆé‡‘é¢ã€ç™¾åˆ†æ¯”ã€æ•°é‡ç­‰ï¼‰
2. æ—¶é—´æ•°æ®ï¼ˆæ—¥æœŸã€æœŸé—´ç­‰ï¼‰
3. åˆ†ç±»æ•°æ®ï¼ˆç±»åˆ«ã€ç­‰çº§ç­‰ï¼‰

ä»¥ç»“æ„åŒ–çš„æ ¼å¼è¾“å‡ºï¼Œä¾¿äºåç»­åˆ†æã€‚
"""
        try:
            extracted_data = await llm.acreate_text(prompt)
            return extracted_data.strip()
        except Exception as e:
            logger.error(f"æ•°æ®æå–å¤±è´¥: {e}")
            return f"æ•°æ®æå–å¤±è´¥: {str(e)}"


class DataAnalysisAction(Action):
    """æ•°æ®åˆ†æåŠ¨ä½œ"""
    
    async def run(self, data: str, analysis_type: str = "è¶‹åŠ¿åˆ†æ") -> str:
        """åˆ†ææ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š"""
        prompt = f"""
ä½ æ˜¯ä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆèµµä¸½å¨…ï¼Œè¯·å¯¹ä»¥ä¸‹æ•°æ®è¿›è¡Œ{analysis_type}ï¼š

æ•°æ®ï¼š
{data}

è¯·æä¾›ï¼š
1. æ•°æ®æ¦‚è§ˆå’ŒåŸºæœ¬ç»Ÿè®¡
2. ä¸»è¦è¶‹åŠ¿å’Œæ¨¡å¼
3. å…³é”®å‘ç°å’Œæ´å¯Ÿ
4. æ•°æ®è´¨é‡è¯„ä¼°
5. åˆ†æç»“è®ºå’Œå»ºè®®

è¯·ç”¨ä¸“ä¸šçš„æ•°æ®åˆ†æè¯­è¨€ï¼Œæä¾›æ¸…æ™°çš„åˆ†æç»“æœã€‚
"""
        try:
            analysis_result = await llm.acreate_text(prompt)
            return analysis_result.strip()
        except Exception as e:
            logger.error(f"æ•°æ®åˆ†æå¤±è´¥: {e}")
            return f"æ•°æ®åˆ†æå¤±è´¥: {str(e)}"


class DataAnalystAgent(BaseAgent):
    """
    ğŸ“Š æ•°æ®åˆ†æå¸ˆï¼ˆèµµä¸½å¨…ï¼‰ - è™šæ‹ŸåŠå…¬å®¤çš„æ•°æ®ä¸“å®¶
    """
    def __init__(self, agent_id: str, session_id: str, workspace_path: str, memory_manager=None):
        super().__init__(
            agent_id=agent_id,
            session_id=session_id,
            workspace_path=workspace_path,
            memory_manager=memory_manager,
            profile="æ•°æ®åˆ†æå¸ˆ",
            goal="è¿›è¡Œæ•°æ®æ”¶é›†ã€ç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–"
        )
        
        # åˆå§‹åŒ–æ•°æ®åˆ†æå·¥å…·
        self.analysis_tools = self._initialize_analysis_tools()
        
        # è®¾ç½®ä¸“å®¶ä¿¡æ¯
        self.name = "èµµä¸½å¨…"
        self.avatar = "ğŸ“Š"
        self.expertise = "æ•°æ®åˆ†æä¸å¯è§†åŒ–"
        
        # è®¾ç½®åŠ¨ä½œ
        self.set_actions([DataExtractionAction, DataAnalysisAction])
        
        # åˆ›å»ºä¸“é—¨çš„å·¥ä½œç›®å½•
        self.data_dir = self.agent_workspace / "data"
        self.charts_dir = self.agent_workspace / "charts"
        self.analysis_dir = self.agent_workspace / "analysis"
        
        for dir_path in [self.data_dir, self.charts_dir, self.analysis_dir]:
            dir_path.mkdir(exist_ok=True)
        
        logger.info(f"ğŸ“Š æ•°æ®åˆ†æå¸ˆ {self.name} åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_analysis_tools(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–æ•°æ®åˆ†æå·¥å…·"""
        return {
            "statistical_analysis": {
                "description": "åŸºç¡€ç»Ÿè®¡åˆ†æå·¥å…·",
                "capabilities": ["å‡å€¼è®¡ç®—", "æ ‡å‡†å·®", "ç›¸å…³æ€§åˆ†æ", "è¶‹åŠ¿åˆ†æ"]
            },
            "data_visualization": {
                "description": "æ•°æ®å¯è§†åŒ–å·¥å…·", 
                "capabilities": ["å›¾è¡¨ç”Ÿæˆ", "æ•°æ®å±•ç¤º", "æŠ¥å‘Šç¾åŒ–"]
            },
            "performance_metrics": {
                "description": "ç»©æ•ˆæŒ‡æ ‡åˆ†æå·¥å…·",
                "capabilities": ["KPIåˆ†æ", "ç›®æ ‡è¾¾æˆç‡", "æ•ˆç‡è¯„ä¼°"]
            }
        }
    
    async def _execute_specific_task(self, task: "Task", context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå…·ä½“çš„æ•°æ®åˆ†æä»»åŠ¡"""
        logger.info(f"ğŸ“Š {self.name} å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.description}")

        # ç®€å•çš„åŸºäºå…³é”®è¯çš„ä»»åŠ¡è·¯ç”±
        if "æå–" in task.description and "æ•°æ®" in task.description:
            # å‡è®¾éœ€è¦åˆ†æçš„å†…å®¹åœ¨ä¸Šä¸‹æ–‡ä¸­
            source_content = ""
            if context:
                # å°è¯•ä»ä¸Šä¸‹æ–‡çš„ä»»ä½•æ¥æºæå–å†…å®¹
                for key, value in context.items():
                    if isinstance(value, dict) and 'result' in value:
                         # ä¼˜å…ˆä½¿ç”¨ä¸Šæ¸¸ä»»åŠ¡çš„resultå­—æ®µ
                        res = value['result']
                        if isinstance(res, dict) and 'content_preview' in res:
                            source_content = res['content_preview']
                            break
                        elif isinstance(res, str):
                            source_content = res
                            break
            
            if not source_content:
                return {"status": "error", "result": "æœªåœ¨ä¸Šä¸‹æ–‡ä¸­æ‰¾åˆ°å¯ä¾›æå–æ•°æ®çš„å†…å®¹"}

            return await self._extract_data({"content": source_content, "data_type": "æ•°å€¼å’Œå…³é”®ä¿¡æ¯"})

        elif "åˆ†æ" in task.description and "æ•°æ®" in task.description:
            # å‡è®¾æ•°æ®åœ¨ä¸Šä¸‹æ–‡ä¸­
            source_data = ""
            if context:
                 for key, value in context.items():
                    if isinstance(value, dict) and 'result' in value:
                        res = value['result']
                        if isinstance(res, dict) and 'extracted_data' in res:
                            source_data = res['extracted_data']
                            break
                        elif isinstance(res, str):
                            source_data = res
                            break
            
            if not source_data:
                return {"status": "error", "result": "æœªåœ¨ä¸Šä¸‹æ–‡ä¸­æ‰¾åˆ°å¯ä¾›åˆ†æçš„æ•°æ®"}
            
            analysis_type_match = re.search(r"è¿›è¡Œ(.*?)åˆ†æ", task.description)
            analysis_type = analysis_type_match.group(1).strip() if analysis_type_match else "ç»¼åˆ"
            
            return await self._analyze_data({"data": source_data, "analysis_type": analysis_type})

        else:
            return {"status": "completed", "result": f"å·²å®Œæˆé€šç”¨æ•°æ®ä»»åŠ¡: {task.description}"}

    async def _extract_data(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """æå–æ•°æ®"""
        try:
            content = task.get('content', '')
            data_type = task.get('data_type', 'æ•°å€¼æ•°æ®')
            
            self.current_task = f"æ­£åœ¨æå–{data_type}"
            self.progress = 10
            
            # æ‰§è¡Œæ•°æ®æå–
            extraction_action = DataExtractionAction()
            extracted_data = await extraction_action.run(content, data_type)
            
            self.progress = 80
            
            # ä¿å­˜æå–ç»“æœ
            data_file = self.data_dir / f"extracted_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            with open(data_file, 'w', encoding='utf-8') as f:
                f.write(f"# æ•°æ®æå–æŠ¥å‘Š\n\n")
                f.write(f"**æå–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**åˆ†æå¸ˆ**: {self.name}\n")
                f.write(f"**æ•°æ®ç±»å‹**: {data_type}\n\n")
                f.write(f"## æå–ç»“æœ\n\n{extracted_data}\n\n")
                f.write(f"---\n*æ•°æ®æå–: {self.name} ğŸ“Š*")
            
            self.progress = 100
            
            result = {
                'agent_id': self.agent_id,
                'status': 'completed',
                'result': f"å·²å®Œæˆ{data_type}çš„æå–",
                'files_created': [data_file.name],
                'extracted_data': extracted_data, # è¿”å›å®Œæ•´æ•°æ®
                'timestamp': datetime.now().isoformat()
            }
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ {self.name} æ•°æ®æå–å¤±è´¥: {e}")
            raise

    async def _analyze_data(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ•°æ®"""
        try:
            data = task.get('data', '')
            analysis_type = task.get('analysis_type', 'è¶‹åŠ¿åˆ†æ')
            
            self.current_task = f"æ­£åœ¨è¿›è¡Œ{analysis_type}"
            self.progress = 10
            
            # å¦‚æœæ²¡æœ‰æä¾›æ•°æ®ï¼Œä»å·²æå–çš„æ•°æ®ä¸­è¯»å–
            if not data:
                data_files = list(self.data_dir.glob("extracted_data_*.md"))
                if data_files:
                    with open(data_files[-1], 'r', encoding='utf-8') as f:
                        data = f.read()
                else:
                    return {
                        'agent_id': self.agent_id,
                        'status': 'completed',
                        'result': "æš‚æ— æ•°æ®å¯ä¾›åˆ†æï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®æå–",
                        'files_created': []
                    }
            
            self.progress = 30
            
            # æ‰§è¡Œæ•°æ®åˆ†æ
            analysis_action = DataAnalysisAction()
            analysis_result = await analysis_action.run(data, analysis_type)
            
            self.progress = 80
            
            # ä¿å­˜åˆ†æç»“æœ
            analysis_file = self.analysis_dir / f"analysis_{analysis_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            with open(analysis_file, 'w', encoding='utf-8') as f:
                f.write(f"# æ•°æ®åˆ†ææŠ¥å‘Š - {analysis_type}\n\n")
                f.write(f"**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**åˆ†æå¸ˆ**: {self.name}\n")
                f.write(f"**åˆ†æç±»å‹**: {analysis_type}\n\n")
                f.write(f"## åˆ†æç»“æœ\n\n{analysis_result}\n\n")
                f.write(f"---\n*æ•°æ®åˆ†æ: {self.name} ğŸ“Š*")
            
            self.progress = 100
            
            result = {
                'agent_id': self.agent_id,
                'status': 'completed',
                'result': f"å·²å®Œæˆ{analysis_type}",
                'files_created': [analysis_file.name],
                'analysis_summary': analysis_result, # è¿”å›å®Œæ•´åˆ†æ
                'timestamp': datetime.now().isoformat()
            }
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ {self.name} æ•°æ®åˆ†æå¤±è´¥: {e}")
            raise

    async def _generate_charts(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå›¾è¡¨"""
        try:
            self.current_task = "æ­£åœ¨ç”Ÿæˆæ•°æ®å›¾è¡¨"
            self.progress = 10
            
            # è¯»å–åˆ†æç»“æœ
            analysis_files = list(self.analysis_dir.glob("analysis_*.md"))
            
            if not analysis_files:
                return {
                    'agent_id': self.agent_id,
                    'status': 'completed',
                    'result': "æš‚æ— åˆ†æç»“æœå¯ä¾›å›¾è¡¨ç”Ÿæˆï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®åˆ†æ",
                    'files_created': []
                }
            
            chart_files = []
            
            for analysis_file in analysis_files[-2:]:  # ä¸ºæœ€è¿‘çš„2ä¸ªåˆ†æç”Ÿæˆå›¾è¡¨
                with open(analysis_file, 'r', encoding='utf-8') as f:
                    analysis_content = f.read()
                
                # ç”Ÿæˆå›¾è¡¨æè¿°ï¼ˆå®é™…é¡¹ç›®ä¸­è¿™é‡Œä¼šç”ŸæˆçœŸå®å›¾è¡¨ï¼‰
                chart_description = f"""# æ•°æ®å¯è§†åŒ–å›¾è¡¨

åŸºäºåˆ†ææ–‡ä»¶: {analysis_file.name}

## å»ºè®®å›¾è¡¨ç±»å‹

1. **è¶‹åŠ¿å›¾**: å±•ç¤ºæ•°æ®éšæ—¶é—´çš„å˜åŒ–è¶‹åŠ¿
2. **æŸ±çŠ¶å›¾**: æ¯”è¾ƒä¸åŒç±»åˆ«çš„æ•°æ®
3. **é¥¼å›¾**: å±•ç¤ºæ•°æ®çš„æ„æˆæ¯”ä¾‹
4. **æ•£ç‚¹å›¾**: å±•ç¤ºå˜é‡é—´çš„ç›¸å…³å…³ç³»

## å›¾è¡¨è¯´æ˜

{analysis_content[:500]}...

*å›¾è¡¨ç”Ÿæˆ: {self.name} ğŸ“Š*
*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
                
                chart_file = self.charts_dir / f"chart_{analysis_file.stem}.md"
                with open(chart_file, 'w', encoding='utf-8') as f:
                    f.write(chart_description)
                
                chart_files.append(chart_file.name)
            
            self.progress = 100
            
            result = {
                'agent_id': self.agent_id,
                'status': 'completed',
                'result': f"å·²ç”Ÿæˆ {len(chart_files)} ä¸ªæ•°æ®å›¾è¡¨",
                'files_created': chart_files,
                'timestamp': datetime.now().isoformat()
            }
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ {self.name} å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
            raise

    async def get_work_summary(self) -> str:
        """è·å–å·¥ä½œæ‘˜è¦"""
        try:
            data_count = len(list(self.data_dir.glob("*.md")))
            analysis_count = len(list(self.analysis_dir.glob("*.md")))
            chart_count = len(list(self.charts_dir.glob("*.md")))
            
            summary = f"ğŸ“Š {self.name} å·¥ä½œæ‘˜è¦:\n"
            summary += f"â€¢ æ•°æ®æå–: {data_count} æ¬¡\n"
            summary += f"â€¢ å®Œæˆåˆ†æ: {analysis_count} ä»½\n"
            summary += f"â€¢ ç”Ÿæˆå›¾è¡¨: {chart_count} ä¸ª\n"
            summary += f"â€¢ å½“å‰çŠ¶æ€: {self.status}\n"
            
            if self.current_task:
                summary += f"â€¢ å½“å‰ä»»åŠ¡: {self.current_task}\n"
            
            return summary
            
        except Exception as e:
            return f"ğŸ“Š {self.name}: å·¥ä½œæ‘˜è¦è·å–å¤±è´¥ - {str(e)}"