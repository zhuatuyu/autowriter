"""
å¢å¼ºç‰ˆæ™ºèƒ½é¡¹ç›®æ€»ç›‘Agent - åŸºäºMetaGPTè®¾è®¡ç†å¿µ
å…·å¤‡æ·±åº¦å®¢æˆ·æ²Ÿé€šã€æ™ºèƒ½ä»»åŠ¡è§„åˆ’å’ŒåŠ¨æ€Agentç¼–æ’èƒ½åŠ›
"""
from metagpt.roles import Role
from metagpt.schema import Message, Plan, Task
from metagpt.logs import logger
from metagpt.strategy.planner import Planner
import json
import os
from typing import Dict, List, Optional, Any
from datetime import datetime
from backend.services.llm.agents.base import BaseAgent


class EnhancedDirectorAgent(BaseAgent):
    """
    ğŸ¯ å¢å¼ºç‰ˆæ™ºèƒ½é¡¹ç›®æ€»ç›‘ - è™šæ‹ŸåŠå…¬å®¤çš„æ ¸å¿ƒç®¡ç†è€…
    
    åŸºäºMetaGPTçš„TeamLeaderå’ŒPlanneræ¨¡å¼è®¾è®¡ï¼Œå…·å¤‡ï¼š
    1. æ·±åº¦å®¢æˆ·æ²Ÿé€šèƒ½åŠ› - å›ç­”å„ç§ä¸“ä¸šé—®é¢˜ï¼Œä¸åªæ˜¯æ„å»ºæŠ¥å‘Šæ¡†æ¶
    2. æ™ºèƒ½ä»»åŠ¡è§„åˆ’ - å°†å¤æ‚éœ€æ±‚æ‹†è§£ä¸ºå¯æ‰§è¡Œä»»åŠ¡
    3. åŠ¨æ€Agentç¼–æ’ - æ ¹æ®éœ€æ±‚è°ƒç”¨åˆé€‚çš„Agentç»„åˆ
    4. ä¸Šä¸‹æ–‡è®°å¿† - ç»´æŠ¤å¯¹è¯å†å²å’Œé¡¹ç›®çŠ¶æ€
    5. çµæ´»å·¥ä½œæµ - ç®€å•é—®é¢˜ç›´æ¥å›ç­”ï¼Œå¤æ‚ä»»åŠ¡å¯åŠ¨å¤šAgentåä½œ
    """
    
    def __init__(self, session_id: str, workspace_path: str, memory_manager=None):
        super().__init__(
            agent_id="enhanced_director",
            session_id=session_id,
            workspace_path=workspace_path,
            memory_manager=memory_manager,
            profile="æ™ºèƒ½é¡¹ç›®æ€»ç›‘",
            goal="é¡¹ç›®ç®¡ç†å’Œå®¢æˆ·æ²Ÿé€šä¸“å®¶"
        )
        
        # è®¾ç½®å¢å¼ºç‰ˆDirectorçš„ç‰¹æœ‰å±æ€§
        self.role = "é¡¹ç›®ç®¡ç†å’Œå®¢æˆ·æ²Ÿé€šä¸“å®¶"
        
        # åˆå§‹åŒ–å¢å¼ºç‰ˆDirectorçš„ç‰¹æœ‰å±æ€§
        self.conversation_context = []
        self.active_tasks = []
        self.current_report_structure = None
        
        # åˆå§‹åŒ–å…¶ä»–å¿…è¦å±æ€§
        self._initialize_capabilities()
        self._initialize_knowledge_base()
    
    def _initialize_capabilities(self):
        """åˆå§‹åŒ–Agentèƒ½åŠ›æ˜ å°„"""
        self.agent_capabilities = {
            "document_expert": {
                "name": "æ–‡æ¡£ä¸“å®¶æå¿ƒæ‚¦",
                "capabilities": ["æ–‡æ¡£ä¸Šä¼ å¤„ç†", "æ ¼å¼è½¬æ¢", "å†…å®¹æ‘˜è¦", "æ–‡æ¡£æ£€ç´¢", "å†å²æ–‡æ¡£æŸ¥æ‰¾", "æ–‡æ¡£ç®¡ç†"],
                "suitable_for": ["æ–‡æ¡£ç›¸å…³é—®é¢˜", "å†å²èµ„æ–™æŸ¥è¯¢", "æ–‡ä»¶å¤„ç†éœ€æ±‚", "æ–‡æ¡£æ ¼å¼è½¬æ¢"],
                "keywords": ["æ–‡æ¡£", "æ–‡ä»¶", "å†å²", "èµ„æ–™", "ä¸Šä¼ ", "æ ¼å¼", "æŸ¥æ‰¾"]
            },
            "case_expert": {
                "name": "æ¡ˆä¾‹ä¸“å®¶ç‹ç£Š", 
                "capabilities": ["æ¡ˆä¾‹æœç´¢", "æœ€ä½³å®è·µåˆ†æ", "è¡Œä¸šå¯¹æ¯”", "å‚è€ƒèµ„æ–™æ”¶é›†", "ç½‘ç»œæœç´¢"],
                "suitable_for": ["æ¡ˆä¾‹æŸ¥æ‰¾", "è¡Œä¸šç»éªŒ", "å‚è€ƒèµ„æ–™éœ€æ±‚", "å¯¹æ¯”åˆ†æ", "æœ€ä½³å®è·µ"],
                "keywords": ["æ¡ˆä¾‹", "å‚è€ƒ", "æœç´¢", "è¡Œä¸š", "ç»éªŒ", "å®è·µ", "å¯¹æ¯”"]
            },
            "data_analyst": {
                "name": "æ•°æ®åˆ†æå¸ˆèµµä¸½å¨…",
                "capabilities": ["æ•°æ®æå–", "ç»Ÿè®¡åˆ†æ", "å›¾è¡¨ç”Ÿæˆ", "æŒ‡æ ‡è®¡ç®—", "æ•°æ®å¯è§†åŒ–"],
                "suitable_for": ["æ•°æ®åˆ†æ", "ç»Ÿè®¡éœ€æ±‚", "æŒ‡æ ‡ç›¸å…³", "é‡åŒ–åˆ†æ", "å›¾è¡¨åˆ¶ä½œ"],
                "keywords": ["æ•°æ®", "åˆ†æ", "ç»Ÿè®¡", "æŒ‡æ ‡", "å›¾è¡¨", "é‡åŒ–", "è®¡ç®—"]
            },
            "writer_expert": {
                "name": "å†™ä½œä¸“å®¶å¼ ç¿°",
                "capabilities": ["å†…å®¹æ’°å†™", "ç« èŠ‚ç¼–å†™", "æ–‡æœ¬æ¶¦è‰²", "ç»“æ„ä¼˜åŒ–", "æŠ¥å‘Šæ’°å†™"],
                "suitable_for": ["å†™ä½œéœ€æ±‚", "å†…å®¹åˆ›ä½œ", "ç« èŠ‚æ’°å†™", "æ–‡æœ¬ä¼˜åŒ–", "æŠ¥å‘Šç¼–å†™"],
                "keywords": ["å†™ä½œ", "æ’°å†™", "å†…å®¹", "ç« èŠ‚", "ç¼–å†™", "åˆ›ä½œ", "æ–‡æœ¬"]
            },
            "chief_editor": {
                "name": "æ€»ç¼–è¾‘é’±æ•",
                "capabilities": ["å†…å®¹å®¡æ ¸", "è´¨é‡æŠŠæ§", "æ ¼å¼è§„èŒƒ", "æœ€ç»ˆæ¶¦è‰²", "æ•´ä½“æŠŠå…³"],
                "suitable_for": ["å®¡æ ¸éœ€æ±‚", "è´¨é‡æ£€æŸ¥", "æœ€ç»ˆç¡®è®¤", "æ ¼å¼è§„èŒƒ", "æ•´ä½“ä¼˜åŒ–"],
                "keywords": ["å®¡æ ¸", "æ£€æŸ¥", "è´¨é‡", "æ ¼å¼", "è§„èŒƒ", "æ¶¦è‰²", "æŠŠå…³"]
            }
        }
    
    def _initialize_knowledge_base(self):
        """åˆå§‹åŒ–ä¸“ä¸šçŸ¥è¯†åº“"""
        self.knowledge_base = {
            "report_writing_tips": {
                "ç»©æ•ˆæŠ¥å‘Šå†™ä½œæŠ€å·§": [
                    "æ˜ç¡®è¯„ä»·ç›®æ ‡å’ŒèŒƒå›´",
                    "å»ºç«‹ç§‘å­¦çš„æŒ‡æ ‡ä½“ç³»", 
                    "æ”¶é›†å……åˆ†çš„æ•°æ®æ”¯æ’‘",
                    "é‡‡ç”¨å®šé‡ä¸å®šæ€§ç›¸ç»“åˆçš„æ–¹æ³•",
                    "æ³¨é‡é€»è¾‘æ€§å’Œæ¡ç†æ€§",
                    "çªå‡ºé—®é¢˜å¯¼å‘å’Œç»“æœå¯¼å‘"
                ]
            },
            "common_frameworks": {
                "å¸¸ç”¨æŠ¥å‘Šæ¡†æ¶": [
                    "èƒŒæ™¯ä¸ç›®æ ‡ â†’ å®æ–½è¿‡ç¨‹ â†’ æˆæ•ˆåˆ†æ â†’ é—®é¢˜ä¸å»ºè®®",
                    "é¡¹ç›®æ¦‚è¿° â†’ ç»©æ•ˆæŒ‡æ ‡ â†’ è¯„ä»·ç»“æœ â†’ æ”¹è¿›æªæ–½",
                    "ç«‹é¡¹èƒŒæ™¯ â†’ æ‰§è¡Œæƒ…å†µ â†’ äº§å‡ºæ•ˆæœ â†’ å½±å“è¯„ä¼°"
                ]
            }
        }
    
    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLMçš„æ–¹æ³• - ä½¿ç”¨MetaGPTçš„LLMæ¥å£"""
        try:
            # åˆ›å»ºæ¶ˆæ¯
            message = Message(content=prompt, role="user")
            
            # ä½¿ç”¨MetaGPTçš„thinkæ–¹æ³•è°ƒç”¨LLM
            response = await self._think()
            
            # å¦‚æœthinkæ–¹æ³•ä¸è¿”å›å­—ç¬¦ä¸²ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨LLM
            if not isinstance(response, str):
                from metagpt.llm import LLM
                llm = LLM()
                response = await llm.aask(prompt)
            
            return response
            
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼š{str(e)}"
        
        # åˆå§‹åŒ–è§„åˆ’å™¨ - å€Ÿé‰´MetaGPTçš„Planneræ¨¡å¼
        self.planner = Planner(goal="ååŠ©ç”¨æˆ·å®Œæˆä¸“ä¸šæŠ¥å‘Šç›¸å…³çš„å„ç§éœ€æ±‚")
        
        # æŠ¥å‘Šæ¨¡æ¿é…ç½®
        self.report_template = self._load_report_template()
    
    def _load_report_template(self) -> dict:
        """åŠ è½½æŠ¥å‘Šæ¨¡æ¿é…ç½®"""
        try:
            template_path = os.path.join(os.path.dirname(__file__), "../../../..", "reportmodel.yaml")
            import yaml
            with open(template_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.error(f"åŠ è½½æŠ¥å‘Šæ¨¡æ¿å¤±è´¥: {e}")
            return {}
    
    async def process_request(self, user_message: str, context: dict = None) -> dict:
        """
        å¤„ç†ç”¨æˆ·è¯·æ±‚çš„ä¸»å…¥å£ - å€Ÿé‰´MetaGPTçš„æ™ºèƒ½åˆ†å‘æœºåˆ¶
        """
        try:
            # æ›´æ–°å¯¹è¯ä¸Šä¸‹æ–‡
            self.conversation_context.append({
                "role": "user",
                "content": user_message,
                "timestamp": self._get_timestamp()
            })
            
            # è¡¥å½•ç”¨æˆ·æ¶ˆæ¯åˆ°ç»Ÿä¸€è®°å¿†
            if hasattr(self, '_memory_adapter') and self._memory_adapter:
                self._memory_adapter.add_simple_message(content=user_message, role="user", cause_by="user_input")

            # æ™ºèƒ½æ„å›¾è¯†åˆ«å’Œéœ€æ±‚åˆ†æ
            intent_analysis = await self._analyze_user_intent(user_message, context)
            
            # æ ¹æ®æ„å›¾é€‰æ‹©å¤„ç†ç­–ç•¥
            response = await self._route_request(user_message, intent_analysis, context)
            
            # è®°å½•å“åº”åˆ°ä¸Šä¸‹æ–‡
            self.conversation_context.append({
                "role": "assistant", 
                "content": response.get("message", ""),
                "timestamp": self._get_timestamp(),
                "intent": intent_analysis
            })
            
            # è¡¥å½•Agentå“åº”åˆ°ç»Ÿä¸€è®°å¿†
            if hasattr(self, '_memory_adapter') and self._memory_adapter:
                self._memory_adapter.add_simple_message(
                    content=response.get("message", ""),
                    role=self.profile,
                    cause_by=f"enhanced_director_response:{intent_analysis.get('intent_type', 'unknown')}"
                )
            
            return response
                
        except Exception as e:
            logger.error(f"Enhanced Directorå¤„ç†è¯·æ±‚å¤±è´¥: {e}")
            return {
                "success": False,
                "message": f"å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "agent_id": self.agent_id,
                "error_type": "processing_error"
            }
    
    async def _analyze_user_intent(self, user_message: str, context: dict = None) -> dict:
        """
        æ™ºèƒ½æ„å›¾è¯†åˆ« - å€Ÿé‰´ä½ åŸæ¥planner.jsçš„åˆ†æé€»è¾‘ï¼Œä½†æ›´åŠ æ™ºèƒ½åŒ–
        """
        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = self._build_context_summary()
        
        analysis_prompt = f"""
        ä½œä¸ºç»éªŒä¸°å¯Œçš„é¡¹ç›®æ€»ç›‘ï¼Œè¯·æ·±åº¦åˆ†æç”¨æˆ·çš„æ„å›¾å’Œéœ€æ±‚ã€‚

        ç”¨æˆ·æ¶ˆæ¯ï¼š{user_message}
        
        å¯¹è¯å†å²æ‘˜è¦ï¼š{context_info}
        
        å½“å‰é¡¹ç›®çŠ¶æ€ï¼š{json.dumps(context or {}, ensure_ascii=False, indent=2)}

        æˆ‘çš„å›¢é˜Ÿæˆå‘˜èƒ½åŠ›ï¼š
        {json.dumps(self.agent_capabilities, ensure_ascii=False, indent=2)}

        è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼çš„ç»“æœï¼š
        {{
            "intent_type": "æ„å›¾ç±»å‹",  // direct_answer, simple_task, complex_workflow, consultation, report_structure
            "complexity": "å¤æ‚åº¦",  // simple, medium, complex
            "required_agents": ["éœ€è¦çš„Agent IDåˆ—è¡¨"],
            "workflow_type": "å·¥ä½œæµç±»å‹",  // single_agent, sequential, parallel, iterative
            "priority": "ä¼˜å…ˆçº§",  // high, medium, low
            "estimated_steps": "é¢„ä¼°æ­¥éª¤æ•°",
            "user_goal": "ç”¨æˆ·çš„æ ¸å¿ƒç›®æ ‡",
            "context_dependencies": "æ˜¯å¦ä¾èµ–å†å²å¯¹è¯",
            "can_answer_directly": "æˆ‘æ˜¯å¦å¯ä»¥ç›´æ¥å›ç­”",
            "reasoning": "è¯¦ç»†çš„åˆ†ææ¨ç†è¿‡ç¨‹"
        }}

        æ„å›¾ç±»å‹è¯´æ˜ï¼š
        - direct_answer: æˆ‘å¯ä»¥ç›´æ¥å›ç­”çš„é—®é¢˜ï¼ˆå¦‚æŠ€å·§å’¨è¯¢ã€æ¦‚å¿µè§£é‡Šã€ç»éªŒåˆ†äº«ï¼‰
        - simple_task: å•ä¸€Agentå¯ä»¥å®Œæˆçš„ç®€å•ä»»åŠ¡ï¼ˆå¦‚æŸ¥æ‰¾æ–‡æ¡£ã€æœç´¢æ¡ˆä¾‹ï¼‰
        - complex_workflow: éœ€è¦å¤šAgentåä½œçš„å¤æ‚å·¥ä½œæµï¼ˆå¦‚å®Œæ•´æŠ¥å‘Šæ’°å†™ï¼‰
        - consultation: ä¸“ä¸šå’¨è¯¢å’Œå»ºè®®ï¼ˆéœ€è¦æˆ‘çš„ä¸“ä¸šåˆ¤æ–­ï¼‰
        - report_structure: æŠ¥å‘Šæ¡†æ¶å’Œç»“æ„è®¾è®¡

        å·¥ä½œæµç±»å‹è¯´æ˜ï¼š
        - single_agent: å•ä¸ªAgentç‹¬ç«‹å®Œæˆ
        - sequential: å¤šAgentæŒ‰é¡ºåºæ‰§è¡Œ
        - parallel: å¤šAgentå¹¶è¡Œæ‰§è¡Œ
        - iterative: éœ€è¦å¤šè½®è¿­ä»£ä¼˜åŒ–

        åˆ¤æ–­åŸåˆ™ï¼š
        1. å¦‚æœæ˜¯è¯¢é—®æŠ€å·§ã€ç»éªŒã€å»ºè®®ç±»é—®é¢˜ï¼Œä¼˜å…ˆé€‰æ‹©direct_answer
        2. å¦‚æœæ˜ç¡®æåˆ°éœ€è¦æŸä¸ªä¸“å®¶çš„æœåŠ¡ï¼Œé€‰æ‹©simple_task
        3. å¦‚æœæ˜¯å¤æ‚çš„æŠ¥å‘Šæ’°å†™éœ€æ±‚ï¼Œé€‰æ‹©complex_workflow
        4. å¦‚æœéœ€è¦ä¸“ä¸šåˆ¤æ–­å’Œå»ºè®®ï¼Œé€‰æ‹©consultation
        """
        
        response = await self._call_llm(analysis_prompt)
        
        try:
            return json.loads(response)
        except:
            return {
                "intent_type": "consultation",
                "complexity": "medium",
                "required_agents": [],
                "workflow_type": "single_agent",
                "priority": "medium",
                "estimated_steps": 1,
                "user_goal": "è·å¾—ä¸“ä¸šå¸®åŠ©",
                "context_dependencies": False,
                "can_answer_directly": True,
                "reasoning": "è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å’¨è¯¢æ¨¡å¼"
            }
    
    async def _route_request(self, user_message: str, intent_analysis: dict, context: dict = None) -> dict:
        """
        æ™ºèƒ½è·¯ç”±åˆ†å‘ - æ ¹æ®æ„å›¾é€‰æ‹©æœ€ä½³å¤„ç†ç­–ç•¥
        """
        intent_type = intent_analysis.get("intent_type", "consultation")
        
        if intent_type == "direct_answer":
            return await self._handle_direct_answer(user_message, intent_analysis)
        elif intent_type == "simple_task":
            return await self._handle_simple_task(user_message, intent_analysis)
        elif intent_type == "complex_workflow":
            return await self._handle_complex_workflow(user_message, intent_analysis)
        elif intent_type == "consultation":
            return await self._handle_consultation(user_message, intent_analysis)
        elif intent_type == "report_structure":
            return await self._handle_report_structure(user_message, intent_analysis)
        else:
            return await self._handle_general_communication(user_message, intent_analysis)
    
    async def _handle_direct_answer(self, user_message: str, intent_analysis: dict) -> dict:
        """
        ç›´æ¥å›ç­”æ¨¡å¼ - å¤„ç†æˆ‘å¯ä»¥ç«‹å³å›ç­”çš„ä¸“ä¸šé—®é¢˜
        è¿™æ˜¯æ–°å¢çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œè®©Directorèƒ½å¤Ÿç›´æ¥å›ç­”ä¸“ä¸šé—®é¢˜
        """
        context_summary = self._build_context_summary()
        
        direct_answer_prompt = f"""
        ä½œä¸ºç»éªŒä¸°å¯Œçš„é¡¹ç›®æ€»ç›‘å’ŒæŠ¥å‘Šå†™ä½œä¸“å®¶ï¼Œè¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

        ç”¨æˆ·é—®é¢˜ï¼š{user_message}
        
        å¯¹è¯ä¸Šä¸‹æ–‡ï¼š{context_summary}
        
        æ„å›¾åˆ†æï¼š{json.dumps(intent_analysis, ensure_ascii=False, indent=2)}

        æˆ‘çš„ä¸“ä¸šçŸ¥è¯†åº“ï¼š
        {json.dumps(self.knowledge_base, ensure_ascii=False, indent=2)}

        è¯·åŸºäºä½ åœ¨ä»¥ä¸‹é¢†åŸŸçš„ä¸°å¯Œç»éªŒæä¾›ä¸“ä¸šå›ç­”ï¼š
        1. é¡¹ç›®ç®¡ç†å’Œåè°ƒ
        2. æŠ¥å‘Šå†™ä½œå’Œç»“æ„è®¾è®¡  
        3. ç»©æ•ˆè¯„ä»·å’ŒæŒ‡æ ‡è®¾è®¡
        4. å›¢é˜Ÿåä½œå’Œå·¥ä½œæµç¨‹
        5. è´¨é‡æ§åˆ¶å’Œæ ‡å‡†è§„èŒƒ

        å›ç­”è¦æ±‚ï¼š
        1. ä¸“ä¸šå‡†ç¡®ï¼ŒåŸºäºå®é™…ç»éªŒ
        2. ç»“æ„æ¸…æ™°ï¼Œé‡ç‚¹çªå‡º  
        3. å®ç”¨æ€§å¼ºï¼Œå¯æ“ä½œ
        4. å¦‚éœ€è¿›ä¸€æ­¥ååŠ©ï¼Œè¯´æ˜å›¢é˜Ÿå¯æä¾›çš„å…·ä½“æœåŠ¡
        5. ä¿æŒå‹å¥½ä¸“ä¸šçš„è¯­è°ƒ

        å¦‚æœé—®é¢˜æ¶‰åŠå…·ä½“çš„æ‰§è¡Œæ“ä½œï¼ˆå¦‚æœç´¢æ¡ˆä¾‹ã€å¤„ç†æ–‡æ¡£ç­‰ï¼‰ï¼Œè¯·è¯´æ˜å¯ä»¥å®‰æ’ç›¸åº”çš„ä¸“å®¶æ¥ååŠ©ã€‚
        """
        
        response = await self._call_llm(direct_answer_prompt)
        
        return {
            "success": True,
            "message": response,
            "agent_id": self.agent_id,
            "response_type": "direct_answer",
            "next_actions": [],
            "workflow_plan": None,
            "follow_up_services": self._suggest_follow_up_services(intent_analysis)
        }
    
    async def _handle_simple_task(self, user_message: str, intent_analysis: dict) -> dict:
        """
        ç®€å•ä»»åŠ¡æ¨¡å¼ - å•ä¸ªAgentå¯ä»¥å®Œæˆçš„ä»»åŠ¡
        """
        required_agents = intent_analysis.get("required_agents", [])
        if not required_agents:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„Agentéœ€æ±‚ï¼Œå°è¯•æ™ºèƒ½åŒ¹é…
            required_agents = self._smart_agent_matching(user_message)
        
        if not required_agents:
            return await self._handle_direct_answer(user_message, intent_analysis)
        
        target_agent = required_agents[0]
        agent_info = self.agent_capabilities.get(target_agent, {})
        
        task_plan = {
            "plan_id": f"simple_task_{self._get_timestamp()}",
            "description": f"å§”æ‰˜{agent_info.get('name', target_agent)}å¤„ç†ç”¨æˆ·éœ€æ±‚",
            "workflow_type": "single_agent",
            "steps": [
                {
                    "step_id": "step_1",
                    "agent_id": target_agent,
                    "action": "process_user_request",
                    "parameters": {
                        "user_message": user_message,
                        "context": self._build_context_summary(),
                        "director_guidance": self._generate_agent_guidance(target_agent, user_message)
                    },
                    "expected_output": "å®Œæˆç”¨æˆ·çš„å…·ä½“éœ€æ±‚",
                    "dependencies": []
                }
            ],
            "estimated_time": "2-5åˆ†é’Ÿ",
            "success_criteria": "ç”¨æˆ·éœ€æ±‚å¾—åˆ°æ»¡è¶³"
        }
        
        response_message = f"""æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ï¼Œè¿™ä¸ªä»»åŠ¡æœ€é€‚åˆç”±æˆ‘ä»¬çš„{agent_info.get('name', target_agent)}æ¥å¤„ç†ã€‚

{agent_info.get('name', target_agent)}çš„ä¸“é•¿åŒ…æ‹¬ï¼š{', '.join(agent_info.get('capabilities', []))}

æˆ‘ç°åœ¨å°±å®‰æ’{agent_info.get('name', target_agent)}ä¸ºæ‚¨å¤„ç†è¿™ä¸ªéœ€æ±‚ï¼Œæˆ‘ä¼šå…¨ç¨‹è·Ÿè¿›ç¡®ä¿è´¨é‡ã€‚"""
        
        return {
            "success": True,
            "message": response_message,
            "agent_id": self.agent_id,
            "response_type": "simple_task",
            "task_plan": task_plan,
            "next_actions": [target_agent]
        }
    
    def _smart_agent_matching(self, user_message: str) -> List[str]:
        """
        æ™ºèƒ½AgentåŒ¹é… - æ ¹æ®ç”¨æˆ·æ¶ˆæ¯å†…å®¹åŒ¹é…æœ€åˆé€‚çš„Agent
        """
        message_lower = user_message.lower()
        matched_agents = []
        
        for agent_id, agent_info in self.agent_capabilities.items():
            keywords = agent_info.get("keywords", [])
            if any(keyword in message_lower for keyword in keywords):
                matched_agents.append(agent_id)
        
        return matched_agents[:2]  # æœ€å¤šè¿”å›2ä¸ªåŒ¹é…çš„Agent
    
    def _generate_agent_guidance(self, agent_id: str, user_message: str) -> str:
        """
        ä¸ºç‰¹å®šAgentç”ŸæˆæŒ‡å¯¼ä¿¡æ¯
        """
        agent_info = self.agent_capabilities.get(agent_id, {})
        return f"""
        ä½œä¸ºé¡¹ç›®æ€»ç›‘ï¼Œæˆ‘ä¸ºæ‚¨æä¾›ä»¥ä¸‹æŒ‡å¯¼ï¼š
        
        ç”¨æˆ·éœ€æ±‚ï¼š{user_message}
        
        æ‚¨çš„ä¸“é•¿ï¼š{', '.join(agent_info.get('capabilities', []))}
        
        è¯·å……åˆ†å‘æŒ¥æ‚¨çš„ä¸“ä¸šèƒ½åŠ›ï¼Œä¸ºç”¨æˆ·æä¾›é«˜è´¨é‡çš„æœåŠ¡ã€‚
        å¦‚é‡åˆ°è¶…å‡ºæ‚¨ä¸“ä¸šèŒƒå›´çš„é—®é¢˜ï¼Œè¯·åŠæ—¶åé¦ˆç»™æˆ‘è¿›è¡Œåè°ƒã€‚
        """
    
    async def _handle_complex_workflow(self, user_message: str, intent_analysis: dict) -> dict:
        """
        å¤æ‚å·¥ä½œæµæ¨¡å¼ - éœ€è¦å¤šAgentåä½œçš„ä»»åŠ¡
        """
        # ä½¿ç”¨è§„åˆ’å™¨ç”Ÿæˆè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’
        workflow_plan = await self._generate_workflow_plan(user_message, intent_analysis)
        
        required_agents = intent_analysis.get("required_agents", [])
        agent_names = [self.agent_capabilities.get(agent_id, {}).get('name', agent_id) for agent_id in required_agents]
        
        response_message = f"""æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ï¼Œè¿™æ˜¯ä¸€ä¸ªéœ€è¦å›¢é˜Ÿåä½œçš„å¤æ‚ä»»åŠ¡ã€‚

å‚ä¸çš„å›¢é˜Ÿæˆå‘˜ï¼š{', '.join(agent_names)}

æ‰§è¡Œè®¡åˆ’ï¼š
{workflow_plan.get('description', 'åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œæ–¹æ¡ˆ')}

é¢„ä¼°å®Œæˆæ—¶é—´ï¼š{workflow_plan.get('estimated_time', '10-30åˆ†é’Ÿ')}

æˆ‘å°†ä½œä¸ºé¡¹ç›®æ€»ç›‘å…¨ç¨‹åè°ƒè¿™ä¸ªå¤æ‚å·¥ä½œæµï¼Œç¡®ä¿å„ä¸ªç¯èŠ‚çš„è´¨é‡å’Œè¿›åº¦ã€‚ç°åœ¨å¼€å§‹æ‰§è¡Œè®¡åˆ’ã€‚"""
        
        return {
            "success": True,
            "message": response_message,
            "agent_id": self.agent_id,
            "response_type": "complex_workflow",
            "task_plan": workflow_plan,
            "next_actions": required_agents
        }
    
    async def _handle_consultation(self, user_message: str, intent_analysis: dict) -> dict:
        """
        ä¸“ä¸šå’¨è¯¢æ¨¡å¼ - æä¾›ä¸“ä¸šå»ºè®®å’ŒæŒ‡å¯¼
        """
        context_summary = self._build_context_summary()
        
        consultation_prompt = f"""
        ä½œä¸ºèµ„æ·±çš„é¡¹ç›®ç®¡ç†ä¸“å®¶å’ŒæŠ¥å‘Šå†™ä½œé¡¾é—®ï¼Œè¯·ä¸ºç”¨æˆ·æä¾›ä¸“ä¸šçš„å’¨è¯¢å»ºè®®ã€‚

        ç”¨æˆ·å’¨è¯¢ï¼š{user_message}
        
        å¯¹è¯èƒŒæ™¯ï¼š{context_summary}
        
        æ„å›¾åˆ†æï¼š{json.dumps(intent_analysis, ensure_ascii=False, indent=2)}

        è¯·åŸºäºä»¥ä¸‹ä¸“ä¸šé¢†åŸŸæä¾›å»ºè®®ï¼š
        1. é¡¹ç›®ç®¡ç†å’Œåè°ƒ
        2. æŠ¥å‘Šå†™ä½œå’Œç»“æ„è®¾è®¡
        3. ç»©æ•ˆè¯„ä»·å’ŒæŒ‡æ ‡è®¾è®¡
        4. å›¢é˜Ÿåä½œå’Œå·¥ä½œæµç¨‹
        5. è´¨é‡æ§åˆ¶å’Œæ ‡å‡†è§„èŒƒ

        å’¨è¯¢å›ç­”è¦æ±‚ï¼š
        1. æä¾›å¤šä¸ªå¯è¡Œçš„è§£å†³æ–¹æ¡ˆ
        2. åˆ†ææ¯ä¸ªæ–¹æ¡ˆçš„ä¼˜ç¼ºç‚¹
        3. ç»™å‡ºå…·ä½“çš„å®æ–½å»ºè®®
        4. è¯´æ˜å¯èƒ½é‡åˆ°çš„é—®é¢˜å’Œåº”å¯¹ç­–ç•¥
        5. å¦‚éœ€è¿›ä¸€æ­¥ååŠ©ï¼Œè¯´æ˜å›¢é˜Ÿå¯æä¾›çš„å…·ä½“æœåŠ¡

        è¯·ä»¥ä¸“ä¸šé¡¾é—®çš„èº«ä»½ï¼Œæä¾›æœ‰ä»·å€¼çš„æŒ‡å¯¼æ„è§ã€‚
        """
        
        response = await self._call_llm(consultation_prompt)
        
        return {
            "success": True,
            "message": response,
            "agent_id": self.agent_id,
            "response_type": "consultation",
            "next_actions": [],
            "follow_up_services": self._suggest_follow_up_services(intent_analysis)
        }
    
    async def _generate_workflow_plan(self, user_message: str, intent_analysis: dict) -> dict:
        """
        ç”Ÿæˆè¯¦ç»†çš„å·¥ä½œæµæ‰§è¡Œè®¡åˆ’ - å€Ÿé‰´MetaGPTçš„è§„åˆ’æœºåˆ¶
        """
        context_summary = self._build_context_summary()
        required_agents = intent_analysis.get("required_agents", [])
        
        planning_prompt = f"""
        ä½œä¸ºé¡¹ç›®æ€»ç›‘ï¼Œè¯·ä¸ºä»¥ä¸‹ç”¨æˆ·éœ€æ±‚åˆ¶å®šè¯¦ç»†çš„å¤šAgentåä½œæ‰§è¡Œè®¡åˆ’ã€‚

        ç”¨æˆ·éœ€æ±‚ï¼š{user_message}
        
        å¯¹è¯èƒŒæ™¯ï¼š{context_summary}
        
        æ„å›¾åˆ†æï¼š{json.dumps(intent_analysis, ensure_ascii=False, indent=2)}

        å¯ç”¨å›¢é˜Ÿæˆå‘˜åŠå…¶èƒ½åŠ›ï¼š
        {json.dumps(self.agent_capabilities, ensure_ascii=False, indent=2)}

        è¯·è¿”å›JSONæ ¼å¼çš„è¯¦ç»†æ‰§è¡Œè®¡åˆ’ï¼š
        {{
            "plan_id": "è®¡åˆ’å”¯ä¸€ID",
            "description": "è®¡åˆ’æ€»ä½“æè¿°",
            "workflow_type": "å·¥ä½œæµç±»å‹",  // sequential, parallel, iterative
            "steps": [
                {{
                    "step_id": "æ­¥éª¤å”¯ä¸€ID",
                    "agent_id": "è´Ÿè´£çš„Agent ID",
                    "action": "å…·ä½“æ‰§è¡ŒåŠ¨ä½œ",
                    "parameters": {{
                        "user_message": "ä¼ é€’ç»™Agentçš„æ¶ˆæ¯",
                        "context": "ä¸Šä¸‹æ–‡ä¿¡æ¯",
                        "specific_requirements": "ç‰¹å®šè¦æ±‚",
                        "director_guidance": "æ€»ç›‘æŒ‡å¯¼"
                    }},
                    "expected_output": "é¢„æœŸè¾“å‡ºæè¿°",
                    "dependencies": ["ä¾èµ–çš„å‰ç½®æ­¥éª¤ID"],
                    "parallel_group": "å¹¶è¡Œç»„IDï¼ˆå¦‚æœé€‚ç”¨ï¼‰",
                    "timeout": "è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"
                }}
            ],
            "estimated_time": "æ€»é¢„ä¼°æ—¶é—´",
            "success_criteria": "æˆåŠŸå®Œæˆçš„æ ‡å‡†",
            "quality_checkpoints": ["è´¨é‡æ£€æŸ¥ç‚¹"],
            "fallback_plan": "å¤‡ç”¨æ–¹æ¡ˆ"
        }}

        è§„åˆ’åŸåˆ™ï¼š
        1. å……åˆ†åˆ©ç”¨æ¯ä¸ªAgentçš„ä¸“ä¸šèƒ½åŠ›
        2. åˆç†å®‰æ’ä»»åŠ¡ä¾èµ–å…³ç³»
        3. è€ƒè™‘å¹¶è¡Œæ‰§è¡Œçš„å¯èƒ½æ€§
        4. è®¾ç½®è´¨é‡æ£€æŸ¥ç‚¹
        5. é¢„ç•™å®¹é”™å’Œè°ƒæ•´ç©ºé—´
        6. ç¡®ä¿æœ€ç»ˆè¾“å‡ºç¬¦åˆç”¨æˆ·æœŸæœ›
        """
        
        response = await self._call_llm(planning_prompt)
        
        try:
            plan = json.loads(response)
            # ä¸ºè®¡åˆ’æ·»åŠ æ—¶é—´æˆ³å’Œä¼šè¯ä¿¡æ¯
            plan["created_at"] = self._get_timestamp()
            plan["session_id"] = self.session_id
            plan["director_id"] = self.agent_id
            return plan
        except:
            # ç”Ÿæˆå¤±è´¥æ—¶çš„å¤‡ç”¨è®¡åˆ’
            return self._generate_fallback_plan(user_message, required_agents, context_summary)
    
    def _generate_fallback_plan(self, user_message: str, required_agents: List[str], context_summary: str) -> dict:
        """ç”Ÿæˆå¤‡ç”¨æ‰§è¡Œè®¡åˆ’"""
        return {
            "plan_id": f"fallback_plan_{self._get_timestamp()}",
            "description": "ç”Ÿæˆè¯¦ç»†è®¡åˆ’å¤±è´¥ï¼Œä½¿ç”¨é¡ºåºæ‰§è¡Œæ¨¡å¼",
            "workflow_type": "sequential",
            "steps": [
                {
                    "step_id": f"step_{i+1}",
                    "agent_id": agent_id,
                    "action": "process_user_request",
                    "parameters": {
                        "user_message": user_message,
                        "context": context_summary,
                        "director_guidance": self._generate_agent_guidance(agent_id, user_message)
                    },
                    "expected_output": f"{self.agent_capabilities.get(agent_id, {}).get('name', agent_id)}çš„å¤„ç†ç»“æœ",
                    "dependencies": [f"step_{i}"] if i > 0 else [],
                    "timeout": 10
                }
                for i, agent_id in enumerate(required_agents)
            ],
            "estimated_time": f"{len(required_agents) * 5}åˆ†é’Ÿ",
            "success_criteria": "å®Œæˆç”¨æˆ·éœ€æ±‚",
            "quality_checkpoints": ["æ¯æ­¥å®Œæˆåæ£€æŸ¥"],
            "fallback_plan": "å¦‚é‡é—®é¢˜ï¼Œè½¬ä¸ºäººå·¥ååŠ©",
            "created_at": self._get_timestamp(),
            "session_id": self.session_id,
            "director_id": self.agent_id
        }
    
    def _build_context_summary(self) -> str:
        """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡æ‘˜è¦"""
        if not self.conversation_context:
            return "è¿™æ˜¯æˆ‘ä»¬å¯¹è¯çš„å¼€å§‹"
        
        # è·å–æœ€è¿‘çš„å‡ è½®å¯¹è¯
        recent_context = self.conversation_context[-6:]  # æœ€è¿‘3è½®å¯¹è¯
        
        summary_parts = []
        for ctx in recent_context:
            role = "ç”¨æˆ·" if ctx["role"] == "user" else "æˆ‘"
            content = ctx["content"][:200] + "..." if len(ctx["content"]) > 200 else ctx["content"]
            summary_parts.append(f"[{role}]: {content}")
        
        return "\n".join(summary_parts)
    
    def _suggest_follow_up_services(self, intent_analysis: dict) -> List[str]:
        """æ ¹æ®æ„å›¾åˆ†æå»ºè®®åç»­æœåŠ¡"""
        services = []
        user_goal = intent_analysis.get("user_goal", "").lower()
        
        if "æ¡ˆä¾‹" in user_goal or "å‚è€ƒ" in user_goal:
            services.append("æ¡ˆä¾‹ä¸“å®¶å¯ä»¥ä¸ºæ‚¨æœç´¢æ›´å¤šç›¸å…³æ¡ˆä¾‹å’Œæœ€ä½³å®è·µ")
        
        if "æ•°æ®" in user_goal or "åˆ†æ" in user_goal or "æŒ‡æ ‡" in user_goal:
            services.append("æ•°æ®åˆ†æå¸ˆå¯ä»¥ä¸ºæ‚¨è¿›è¡Œæ·±åº¦æ•°æ®åˆ†æå’ŒæŒ‡æ ‡è®¾è®¡")
        
        if "å†™ä½œ" in user_goal or "æ’°å†™" in user_goal or "å†…å®¹" in user_goal:
            services.append("å†™ä½œä¸“å®¶å¯ä»¥ååŠ©æ‚¨å®Œæˆå…·ä½“çš„å†™ä½œå’Œå†…å®¹åˆ›ä½œä»»åŠ¡")
        
        if "æ–‡æ¡£" in user_goal or "æ–‡ä»¶" in user_goal:
            services.append("æ–‡æ¡£ä¸“å®¶å¯ä»¥å¸®æ‚¨å¤„ç†å’Œç®¡ç†ç›¸å…³æ–‡æ¡£èµ„æ–™")
        
        if "å®¡æ ¸" in user_goal or "æ£€æŸ¥" in user_goal or "è´¨é‡" in user_goal:
            services.append("æ€»ç¼–è¾‘å¯ä»¥ä¸ºæ‚¨è¿›è¡Œä¸“ä¸šçš„å†…å®¹å®¡æ ¸å’Œè´¨é‡æŠŠæ§")
        
        return services
    
    def _get_timestamp(self) -> str:
        """è·å–æ—¶é—´æˆ³"""
        return datetime.now().strftime("%Y%m%d_%H%M%S")
    
    async def _handle_report_structure(self, user_message: str, intent_analysis: dict) -> dict:
        """
        å¤„ç†æŠ¥å‘Šç»“æ„ç›¸å…³çš„è¯·æ±‚
        """
        context_summary = self._build_context_summary()
        
        structure_prompt = f"""
        ä½œä¸ºé¡¹ç›®æ€»ç›‘å’ŒæŠ¥å‘Šç»“æ„è®¾è®¡ä¸“å®¶ï¼Œè¯·å¤„ç†å…³äºæŠ¥å‘Šç»“æ„çš„éœ€æ±‚ã€‚

        ç”¨æˆ·éœ€æ±‚ï¼š{user_message}
        
        å¯¹è¯èƒŒæ™¯ï¼š{context_summary}
        
        æ„å›¾åˆ†æï¼š{json.dumps(intent_analysis, ensure_ascii=False, indent=2)}
        
        å½“å‰æŠ¥å‘Šæ¨¡æ¿ï¼š{json.dumps(self.report_template, ensure_ascii=False, indent=2)}

        è¯·åŸºäºä»¥ä¸‹æ–¹é¢æä¾›ä¸“ä¸šçš„æŠ¥å‘Šç»“æ„å»ºè®®ï¼š
        1. æŠ¥å‘Šæ•´ä½“æ¡†æ¶è®¾è®¡
        2. ç« èŠ‚é€»è¾‘å…³ç³»
        3. å†…å®¹å±‚æ¬¡ç»“æ„
        4. æŒ‡æ ‡ä½“ç³»è®¾è®¡
        5. æ ¼å¼è§„èŒƒè¦æ±‚

        å¦‚æœéœ€è¦å…·ä½“çš„ç»“æ„è®¾è®¡æˆ–æ¨¡æ¿åˆ¶å®šï¼Œæˆ‘å¯ä»¥åè°ƒå†™ä½œä¸“å®¶å’Œæ€»ç¼–è¾‘æ¥å®Œæˆè¯¦ç»†çš„è®¾è®¡å·¥ä½œã€‚
        """
        
        response = await self._call_llm(structure_prompt)
        
        return {
            "success": True,
            "message": response,
            "agent_id": self.agent_id,
            "response_type": "structure_guidance",
            "next_actions": [],
            "suggested_agents": ["writer_expert", "chief_editor"]
        }
    
    async def _handle_general_communication(self, user_message: str, intent_analysis: dict) -> dict:
        """
        å¤„ç†ä¸€èˆ¬æ€§æ²Ÿé€š
        """
        context_summary = self._build_context_summary()
        
        communication_prompt = f"""
        ä½œä¸ºå‹å¥½ä¸“ä¸šçš„é¡¹ç›®æ€»ç›‘ï¼Œè¯·ä¸ç”¨æˆ·è¿›è¡Œè‡ªç„¶çš„æ²Ÿé€šäº¤æµã€‚

        ç”¨æˆ·æ¶ˆæ¯ï¼š{user_message}
        
        å¯¹è¯èƒŒæ™¯ï¼š{context_summary}
        
        æ„å›¾åˆ†æï¼š{json.dumps(intent_analysis, ensure_ascii=False, indent=2)}

        è¯·ä¿æŒä»¥ä¸‹æ²Ÿé€šé£æ ¼ï¼š
        1. ä¸“ä¸šè€Œå‹å¥½çš„æ€åº¦
        2. ä¸»åŠ¨äº†è§£ç”¨æˆ·éœ€æ±‚
        3. æä¾›æœ‰ä»·å€¼çš„å»ºè®®
        4. å¼•å¯¼ç”¨æˆ·æ˜ç¡®å…·ä½“éœ€æ±‚
        5. ä»‹ç»å›¢é˜Ÿèƒ½æä¾›çš„æœåŠ¡

        å¦‚æœç”¨æˆ·éœ€æ±‚ä¸å¤Ÿæ˜ç¡®ï¼Œè¯·å‹å¥½åœ°è¯¢é—®æ›´å¤šç»†èŠ‚ï¼Œä»¥ä¾¿ä¸ºå…¶æä¾›æ›´å¥½çš„æœåŠ¡ã€‚
        """
        
        response = await self._call_llm(communication_prompt)
        
        return {
            "success": True,
            "message": response,
            "agent_id": self.agent_id,
            "response_type": "communication",
            "next_actions": []
        }
    
    def get_work_context(self) -> dict:
        """è·å–å·¥ä½œä¸Šä¸‹æ–‡"""
        return {
            "agent_id": self.agent_id,
            "name": self.name,
            "role": self.role,
            "current_report_structure": self.current_report_structure,
            "active_tasks": self.active_tasks,
            "report_template": self.report_template,
            "conversation_context": self.conversation_context[-10:],  # æœ€è¿‘10è½®å¯¹è¯
            "agent_capabilities": self.agent_capabilities,
            "planner_status": {
                "current_goal": self.planner.plan.goal if self.planner.plan else None,
                "active_tasks": len(self.active_tasks)
            },
            "knowledge_base": self.knowledge_base
        }
    
    async def update_plan(self, new_goal: str) -> dict:
        """
        æ›´æ–°è§„åˆ’ç›®æ ‡ - å€Ÿé‰´MetaGPTçš„åŠ¨æ€è§„åˆ’èƒ½åŠ›
        """
        try:
            await self.planner.update_plan(goal=new_goal)
            return {
                "success": True,
                "message": f"è§„åˆ’ç›®æ ‡å·²æ›´æ–°ä¸º: {new_goal}",
                "new_goal": new_goal,
                "tasks": [task.dict() for task in self.planner.plan.tasks]
            }
        except Exception as e:
            logger.error(f"æ›´æ–°è§„åˆ’å¤±è´¥: {e}")
            return {
                "success": False,
                "message": f"æ›´æ–°è§„åˆ’å¤±è´¥: {str(e)}"
            }
    
    def get_current_plan_status(self) -> dict:
        """è·å–å½“å‰è§„åˆ’çŠ¶æ€"""
        if not self.planner.plan:
            return {"status": "no_plan", "message": "å½“å‰æ²¡æœ‰æ´»è·ƒçš„è§„åˆ’"}
        
        return {
            "goal": self.planner.plan.goal,
            "current_task": self.planner.current_task.dict() if self.planner.current_task else None,
            "total_tasks": len(self.planner.plan.tasks),
            "completed_tasks": len([t for t in self.planner.plan.tasks if t.is_finished]),
            "progress": f"{len([t for t in self.planner.plan.tasks if t.is_finished])}/{len(self.planner.plan.tasks)}"
        }