"""
MetaGPTæ ‡å‡†çš„æ‘˜è¦Action
ä»ç°æœ‰toolsä¸­å‡çº§çš„æ‘˜è¦èƒ½åŠ›
"""
from typing import List
from metagpt.actions import Action
from metagpt.schema import Message
from metagpt.logs import logger
from backend.configs.llm_provider import llm
from backend.prompts import writer_expert_prompts


class SummarizeAction(Action):
    """
    æ ‡å‡†çš„MetaGPTæ‘˜è¦Action
    ç”¨äºå¯¹æ–‡æœ¬å†…å®¹è¿›è¡Œæ™ºèƒ½æ‘˜è¦
    """
    name: str = "SummarizeText"
    
    async def run(self, history_messages: List[Message], content: str = "") -> str:
        """
        æ‰§è¡Œæ‘˜è¦ä»»åŠ¡
        
        Args:
            history_messages: MetaGPTæ ‡å‡†çš„æ¶ˆæ¯å†å²
            content: éœ€è¦æ‘˜è¦çš„å†…å®¹
            
        Returns:
            str: æ‘˜è¦ç»“æœ
        """
        logger.info(f"ğŸ“ SummarizeAction å¼€å§‹æ‰§è¡Œ")
        
        # å¦‚æœæ²¡æœ‰æä¾›contentï¼Œä»history_messagesä¸­æå–
        if not content and history_messages:
            contents = []
            for msg in history_messages:
                if hasattr(msg, 'content') and msg.content:
                    contents.append(msg.content)
            content = "\n\n".join(contents)
        
        if not content:
            return "é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°éœ€è¦æ‘˜è¦çš„å†…å®¹"
        
        # ä½¿ç”¨ç°æœ‰çš„promptæ¨¡æ¿
        prompt = writer_expert_prompts.get_summary_prompt(
            text_to_summarize=content,
            writer_name="å†™ä½œä¸“å®¶"
        )
        
        try:
            result = await llm.acreate_text(prompt)
            logger.info(f"âœ… SummarizeAction å®Œæˆ: ç”Ÿæˆäº† {len(result)} å­—ç¬¦çš„æ‘˜è¦")
            return result
        except Exception as e:
            error_msg = f"SummarizeAction æ‰§è¡Œå¤±è´¥: {e}"
            logger.error(error_msg)
            return f"# æ‘˜è¦å¤±è´¥\n\n{error_msg}" 