"""
MetaGPTæ ‡å‡†çš„å†™ä½œAction
ä»WriterExpertä¸­æŠ½ç¦»çš„æ ¸å¿ƒå†™ä½œèƒ½åŠ›
"""
from typing import List
from metagpt.actions import Action
from metagpt.schema import Message
from metagpt.logs import logger
from backend.configs.llm_provider import llm
from backend.prompts import writer_expert_prompts


class WriteContentAction(Action):
    """
    æ ‡å‡†çš„MetaGPTå†™ä½œAction
    ç”¨äºåˆ›å»ºå„ç§ç±»å‹çš„æ–‡æ¡£å†…å®¹
    """
    name: str = "WriteContent"
    
    async def run(self, history_messages: List[Message], instruction: str = "", context_str: str = "") -> str:
        """
        æ‰§è¡Œå†™ä½œä»»åŠ¡
        
        Args:
            history_messages: MetaGPTæ ‡å‡†çš„æ¶ˆæ¯å†å²
            instruction: å†™ä½œæŒ‡ä»¤
            context_str: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            str: ç”Ÿæˆçš„å†…å®¹
        """
        logger.info(f"ğŸ–‹ï¸ WriteContentAction å¼€å§‹æ‰§è¡Œ: {instruction}")
        
        # å¦‚æœæ²¡æœ‰æä¾›context_strï¼Œä»history_messagesä¸­æå–
        if not context_str and history_messages:
            contents = []
            for msg in history_messages:
                if hasattr(msg, 'content') and msg.content:
                    contents.append(f"### æ¥æº: {getattr(msg, 'sent_from', 'æœªçŸ¥')}\n\n{msg.content}")
            context_str = "\n\n---\n\n".join(contents)
        
        # ä½¿ç”¨ç°æœ‰çš„promptæ¨¡æ¿
        prompt = writer_expert_prompts.get_content_creation_prompt(
            topic=instruction,
            outline=context_str,
            writer_name="å†™ä½œä¸“å®¶"
        )
        
        try:
            result = await llm.acreate_text(prompt)
            logger.info(f"âœ… WriteContentAction å®Œæˆ: ç”Ÿæˆäº† {len(result)} å­—ç¬¦çš„å†…å®¹")
            return result
        except Exception as e:
            error_msg = f"WriteContentAction æ‰§è¡Œå¤±è´¥: {e}"
            logger.error(error_msg)
            return f"# å†™ä½œå¤±è´¥\n\n{error_msg}" 