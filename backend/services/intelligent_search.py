"""
ğŸ§  æ™ºèƒ½æ£€ç´¢ç»Ÿä¸€æ¥å£
ç»Ÿä¸€ç®¡ç†å‘é‡æ£€ç´¢ã€çŸ¥è¯†å›¾è°±æŸ¥è¯¢å’ŒFLAREä¸»åŠ¨æ£€ç´¢
ä¸ºæ‰€æœ‰actionæä¾›æœ€æ™ºèƒ½çš„æ£€ç´¢èƒ½åŠ›
"""

from typing import List, Dict, Optional, Literal
from metagpt.logs import logger
from .hybrid_search import hybrid_search
from .knowledge_graph import performance_kg



class IntelligentSearchService:
    """ğŸ§  æ™ºèƒ½æ£€ç´¢æœåŠ¡ - åŒæ ¸å¿ƒæ£€ç´¢æ¶æ„
    
    æä¾›ä¸¤ç§æ ¸å¿ƒæ£€ç´¢æ–¹å¼ï¼š
    1. ğŸ” å‘é‡æ£€ç´¢ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„å¿«é€ŸåŒ¹é…
    2. ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±ï¼šåŸºäºå®ä½“å…³ç³»çš„ç»“æ„åŒ–æ¨ç†
    
    æ”¯æŒæ¨¡å¼ï¼š
    - vector: çº¯å‘é‡æ£€ç´¢
    - knowledge_graph: çº¯çŸ¥è¯†å›¾è°±æ£€ç´¢  
    - hybrid: åŒæ ¸å¿ƒæ··åˆæ£€ç´¢ï¼ˆæ¨èï¼‰
    """
    
    def __init__(self):
        self._search_modes = {
            "vector": "å‘é‡æ£€ç´¢",
            "knowledge_graph": "çŸ¥è¯†å›¾è°±æ¨ç†",
            "flare": "FLAREä¸»åŠ¨æ£€ç´¢",
            "hybrid": "æ··åˆæ™ºèƒ½æ£€ç´¢"
        }
    
    async def intelligent_search(
        self,
        query: str,
        project_vector_storage_path: str = "",
        mode: Literal["vector", "knowledge_graph", "flare", "hybrid"] = "hybrid",
        enable_global: bool = True,
        max_results: int = 5
    ) -> Dict[str, any]:
        """
        ğŸ§  æ™ºèƒ½æ£€ç´¢ç»Ÿä¸€å…¥å£
        
        Args:
            query: æŸ¥è¯¢é—®é¢˜
            project_vector_storage_path: é¡¹ç›®çŸ¥è¯†åº“è·¯å¾„
            mode: æ£€ç´¢æ¨¡å¼
            enable_global: æ˜¯å¦å¯ç”¨å…¨å±€çŸ¥è¯†åº“
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
            
        Returns:
            DictåŒ…å«results, mode_used, insightsç­‰
        """
        logger.info(f"ğŸ§  æ™ºèƒ½æ£€ç´¢å¼€å§‹: {query}, æ¨¡å¼: {mode}")
        
        try:
            if mode == "vector":
                return await self._vector_search(query, project_vector_storage_path, enable_global, max_results)
            elif mode == "knowledge_graph":
                return await self._knowledge_graph_search(query, project_vector_storage_path, max_results)

            elif mode == "hybrid":
                return await self._hybrid_intelligent_search(query, project_vector_storage_path, enable_global, max_results)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ£€ç´¢æ¨¡å¼: {mode}")
                
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½æ£€ç´¢å¤±è´¥: {e}")
            return {
                "results": [],
                "mode_used": "error",
                "error": str(e),
                "insights": []
            }
    
    async def _vector_search(
        self, 
        query: str, 
        project_path: str, 
        enable_global: bool, 
        max_results: int
    ) -> Dict[str, any]:
        """ğŸ“Š å‘é‡æ£€ç´¢æ¨¡å¼"""
        try:
            results = await hybrid_search.hybrid_search(
                query=query,
                project_vector_storage_path=project_path,
                enable_global=enable_global,
                global_top_k=max_results//2,
                project_top_k=max_results//2
            )
            
            return {
                "results": results or [],
                "mode_used": "vector",
                "insights": [f"ğŸ“Š åŸºäºå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢åˆ° {len(results or [])} æ¡ç›¸å…³å†…å®¹"],
                "search_summary": f"å‘é‡æ£€ç´¢æ¨¡å¼ï¼ŒæŸ¥è¯¢: {query}"
            }
            
        except Exception as e:
            logger.error(f"âŒ å‘é‡æ£€ç´¢å¤±è´¥: {e}")
            return {"results": [], "mode_used": "vector_error", "error": str(e), "insights": []}
    
    async def _knowledge_graph_search(
        self, 
        query: str, 
        project_path: str, 
        max_results: int
    ) -> Dict[str, any]:
        """ğŸ§  çŸ¥è¯†å›¾è°±æ¨ç†æ¨¡å¼"""
        try:
            # é¦–å…ˆå°è¯•ä»é¡¹ç›®çŸ¥è¯†å›¾è°±æŸ¥è¯¢
            kg_result = ""
            if project_path:
                try:
                    kg_result = await performance_kg.query_knowledge_graph(
                        query=query,
                        mode="keyword",  # ä¿®å¤ï¼šä½¿ç”¨æ”¯æŒçš„æ¨¡å¼
                        max_knowledge_sequence=max_results
                    )
                except Exception as e:
                    logger.warning(f"é¡¹ç›®çŸ¥è¯†å›¾è°±æŸ¥è¯¢å¤±è´¥: {e}")
            
            # å¦‚æœé¡¹ç›®KGå¤±è´¥æˆ–æ²¡æœ‰ç»“æœï¼Œå°è¯•å…¨å±€çŸ¥è¯†å›¾è°±
            if not kg_result or "çŸ¥è¯†å›¾è°±ä¸å¯ç”¨" in kg_result:
                # è¿™é‡Œå¯ä»¥æ‰©å±•æ”¯æŒå…¨å±€çŸ¥è¯†å›¾è°±
                kg_result = "çŸ¥è¯†å›¾è°±åŠŸèƒ½æ­£åœ¨å‡†å¤‡ä¸­"
            
            # è§£æçŸ¥è¯†å›¾è°±ç»“æœ
            insights = self._extract_kg_insights(kg_result)
            
            return {
                "results": [kg_result] if kg_result else [],
                "mode_used": "knowledge_graph",
                "insights": insights,
                "search_summary": f"çŸ¥è¯†å›¾è°±æ¨ç†æ¨¡å¼ï¼ŒæŸ¥è¯¢: {query}",
                "entities_relations": self._extract_entities_from_kg_result(kg_result)
            }
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†å›¾è°±æŸ¥è¯¢å¤±è´¥: {e}")
            return {"results": [], "mode_used": "kg_error", "error": str(e), "insights": []}
    

    
    async def _hybrid_intelligent_search(
        self, 
        query: str, 
        project_path: str, 
        enable_global: bool, 
        max_results: int
    ) -> Dict[str, any]:
        """ğŸš€ æ··åˆæ™ºèƒ½æ£€ç´¢æ¨¡å¼ - å¤šç§æ–¹æ³•ç»“åˆ"""
        logger.info("ğŸš€ å¯åŠ¨æ··åˆæ™ºèƒ½æ£€ç´¢...")
        
        # ğŸ§  æŸ¥è¯¢æ„å›¾åˆ†æ
        search_strategy = await self._analyze_query_intent(query)
        
        # ğŸ”„ å¹¶è¡Œæ‰§è¡Œå¤šç§æ£€ç´¢æ–¹æ³•
        import asyncio
        
        tasks = []
        
        # å‘é‡æ£€ç´¢ï¼ˆåŸºç¡€ï¼‰
        tasks.append(self._vector_search(query, project_path, enable_global, max_results))
        
        # æ ¹æ®æŸ¥è¯¢æ„å›¾é€‰æ‹©å…¶ä»–æ–¹æ³•
        if search_strategy["use_kg"]:
            tasks.append(self._knowledge_graph_search(query, project_path, max_results))
        

        
        # å¹¶è¡Œæ‰§è¡Œ
        search_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ğŸ§  æ™ºèƒ½ç»“æœèåˆ
        hybrid_result = await self._merge_search_results(search_results, query, search_strategy)
        
        return hybrid_result
    
    async def _analyze_query_intent(self, query: str) -> Dict[str, bool]:
        """ğŸ§  æŸ¥è¯¢æ„å›¾åˆ†æï¼Œå†³å®šä½¿ç”¨å“ªäº›æ£€ç´¢æ–¹æ³•"""
        strategy = {
            "use_kg": False,
            "use_flare": False,
            "query_type": "general"
        }
        
        # å…³ç³»æ¨ç†æŸ¥è¯¢ - é€‚åˆçŸ¥è¯†å›¾è°±
        if any(keyword in query for keyword in [
            "å…³ç³»", "è”ç³»", "å½±å“", "å¯¼è‡´", "åŸå› ", "å› ç´ ",
            "å¦‚ä½•", "ä¸ºä»€ä¹ˆ", "ä»€ä¹ˆæ˜¯", "ç±»ä¼¼", "ç›¸å…³çš„"
        ]):
            strategy["use_kg"] = True
            strategy["query_type"] = "reasoning"
        
        # å¤æ‚æ¢ç´¢æŸ¥è¯¢ - é€‚åˆFLARE
        if any(keyword in query for keyword in [
            "æ·±å…¥", "è¯¦ç»†", "å…¨é¢", "åˆ†æ", "ç ”ç©¶", "æ¢è®¨", "ç»¼åˆ"
        ]) or len(query) > 20:
            strategy["use_flare"] = True
            strategy["query_type"] = "exploration"
        
        # ç»©æ•ˆè¯„ä»·ä¸“ä¸šæŸ¥è¯¢ - çŸ¥è¯†å›¾è°±ä¼˜å…ˆ
        if any(keyword in query for keyword in [
            "ç»©æ•ˆ", "è¯„ä»·", "æŒ‡æ ‡", "ä½“ç³»", "å†³ç­–", "è¿‡ç¨‹", "äº§å‡º", "æ•ˆç›Š"
        ]):
            strategy["use_kg"] = True
            strategy["query_type"] = "performance"
        
        logger.debug(f"ğŸ§  æŸ¥è¯¢æ„å›¾åˆ†æ: {strategy}")
        return strategy
    
    async def _merge_search_results(
        self, 
        search_results: List[Dict], 
        query: str, 
        strategy: Dict
    ) -> Dict[str, any]:
        """ğŸ§  æ™ºèƒ½ç»“æœèåˆ"""
        merged_results = []
        all_insights = []
        modes_used = []
        
        for result in search_results:
            if isinstance(result, dict) and not isinstance(result, Exception):
                if result.get("results"):
                    merged_results.extend(result["results"])
                if result.get("insights"):
                    all_insights.extend(result["insights"])
                if result.get("mode_used"):
                    modes_used.append(result["mode_used"])
        
        # ğŸ§  ç»“æœå»é‡å’Œæ’åº
        unique_results = self._deduplicate_and_rank_results(merged_results, query)
        
        # ğŸ§  ç”Ÿæˆç»¼åˆæ´å¯Ÿ
        comprehensive_insights = self._generate_comprehensive_insights(
            unique_results, all_insights, strategy, query
        )
        
        return {
            "results": unique_results,
            "mode_used": "hybrid_intelligent",
            "modes_combined": modes_used,
            "insights": comprehensive_insights,
            "search_summary": f"æ··åˆæ™ºèƒ½æ£€ç´¢ï¼Œç»“åˆäº†{len(modes_used)}ç§æ£€ç´¢æ–¹æ³•",
            "strategy_used": strategy
        }
    
    def _deduplicate_and_rank_results(self, results: List[str], query: str) -> List[str]:
        """ğŸ§  ç»“æœå»é‡å’Œæ™ºèƒ½æ’åº"""
        if not results:
            return []
        
        # ç®€å•å»é‡ï¼ˆåŸºäºå†…å®¹ç›¸ä¼¼åº¦ï¼‰
        unique_results = []
        for result in results:
            # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰ç»“æœé‡å¤ï¼ˆç®€å•å­—ç¬¦ä¸²åŒ¹é…ï¼‰
            is_duplicate = False
            for existing in unique_results:
                if len(result) > 50 and len(existing) > 50:
                    # æ£€æŸ¥é•¿ç»“æœçš„é‡å¤åº¦
                    overlap = len(set(result.split()) & set(existing.split()))
                    total_words = len(set(result.split()) | set(existing.split()))
                    if overlap / total_words > 0.7:  # 70%é‡å¤åº¦é˜ˆå€¼
                        is_duplicate = True
                        break
            
            if not is_duplicate:
                unique_results.append(result)
        
        # ç®€å•æ’åºï¼šè¾ƒé•¿çš„ã€åŒ…å«æŸ¥è¯¢å…³é”®è¯çš„ç»“æœä¼˜å…ˆ
        query_keywords = set(query.lower().split())
        
        def relevance_score(text: str) -> float:
            text_lower = text.lower()
            keyword_matches = sum(1 for kw in query_keywords if kw in text_lower)
            length_factor = min(len(text) / 1000, 1.0)  # é•¿åº¦å› å­ï¼Œæœ€å¤§1.0
            return keyword_matches + length_factor
        
        unique_results.sort(key=relevance_score, reverse=True)
        
        return unique_results[:5]  # è¿”å›æœ€ç›¸å…³çš„5ä¸ªç»“æœ
    
    def _generate_comprehensive_insights(
        self, 
        results: List[str], 
        all_insights: List[str], 
        strategy: Dict, 
        query: str
    ) -> List[str]:
        """ğŸ§  ç”Ÿæˆç»¼åˆæ´å¯Ÿ"""
        insights = []
        
        # åŸºç¡€ç»Ÿè®¡æ´å¯Ÿ
        if results:
            insights.append(f"ğŸ§  æ™ºèƒ½æ£€ç´¢å‘ç° {len(results)} æ¡ç›¸å…³ä¿¡æ¯")
        
        # ç­–ç•¥ç›¸å…³æ´å¯Ÿ
        if strategy["query_type"] == "reasoning":
            insights.append("ğŸ•¸ï¸ æ£€æµ‹åˆ°å…³ç³»æ¨ç†æŸ¥è¯¢ï¼Œå·²å¯ç”¨çŸ¥è¯†å›¾è°±åˆ†æ")
        elif strategy["query_type"] == "exploration":
            insights.append("ğŸ” æ£€æµ‹åˆ°æ¢ç´¢æ€§æŸ¥è¯¢ï¼Œå·²å¯ç”¨æ·±åº¦å‘é‡æ£€ç´¢")
        elif strategy["query_type"] == "performance":
            insights.append("ğŸ“Š æ£€æµ‹åˆ°ç»©æ•ˆè¯„ä»·ä¸“ä¸šæŸ¥è¯¢ï¼Œå·²ä¼˜åŒ–æ£€ç´¢ç­–ç•¥")
        
        # åˆå¹¶å…¶ä»–æ´å¯Ÿ
        unique_insights = list(dict.fromkeys(all_insights))  # å»é‡
        insights.extend(unique_insights[:3])  # æœ€å¤šä¿ç•™3ä¸ªé¢å¤–æ´å¯Ÿ
        
        return insights
    
    def _extract_kg_insights(self, kg_result: str) -> List[str]:
        """ä»çŸ¥è¯†å›¾è°±ç»“æœä¸­æå–æ´å¯Ÿ"""
        insights = []
        
        if "### ğŸ•¸ï¸ å‘ç°çš„å®ä½“å…³ç³»" in kg_result:
            insights.append("ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±å‘ç°äº†å®ä½“é—´çš„å…³ç³»")
        
        if "### ğŸ’¡ ç»©æ•ˆåˆ†ææ´å¯Ÿ" in kg_result:
            insights.append("ğŸ’¡ çŸ¥è¯†å›¾è°±ç”Ÿæˆäº†ç»©æ•ˆåˆ†æä¸“ä¸šæ´å¯Ÿ")
        
        if not insights:
            insights.append("ğŸ§  çŸ¥è¯†å›¾è°±æä¾›äº†ç»“æ„åŒ–æ¨ç†ç»“æœ")
        
        return insights
    
    def _extract_entities_from_kg_result(self, kg_result: str) -> Dict[str, List[str]]:
        """ä»çŸ¥è¯†å›¾è°±ç»“æœä¸­æå–å®ä½“å…³ç³»"""
        # è¿™é‡Œå¯ä»¥è§£æçŸ¥è¯†å›¾è°±ç»“æœä¸­çš„å®ä½“å…³ç³»ä¿¡æ¯
        # ç®€åŒ–å®ç°
        return {}


# å…¨å±€å®ä¾‹
intelligent_search = IntelligentSearchService()