#!/usr/bin/env python
"""
å†™ä½œä¸“å®¶Actioné›†åˆ - å†…å®¹ç”Ÿæˆå’Œæ•´åˆï¼ˆSOP2 ç« èŠ‚å†™ä½œï¼‰
"""
import pandas as pd
from pathlib import Path
from metagpt.actions import Action
from metagpt.logs import logger
from backend.services.intelligent_search import intelligent_search
from backend.config.writer_prompts import (
    WRITER_BASE_SYSTEM as ENV_WRITER_BASE_SYSTEM,
    SECTION_WRITING_PROMPT as ENV_SECTION_WRITING_PROMPT,
)
from backend.tools.json_utils import extract_json_from_llm_response
from backend.tools.project_info import get_project_info_text
from .project_manager_action import Task


class WriteSection(Action):
    """
    å†™ä½œç« èŠ‚Action - WriterExpertçš„æ ¸å¿ƒèƒ½åŠ›
    é›†æˆRAGæ£€ç´¢ï¼Œç»“åˆäº‹å®ä¾æ®å’Œæ•°æ®ç”Ÿæˆç« èŠ‚å†…å®¹
    """
    
    async def run(
        self, 
        task: Task, 
        vector_store_path: str, 
        metric_table_json: str
    ) -> str:
        """
        åŸºäºä»»åŠ¡è¦æ±‚ã€å‘é‡ç´¢å¼•å’ŒæŒ‡æ ‡æ•°æ®ç”Ÿæˆç« èŠ‚å†…å®¹
        """
        logger.info(f"å¼€å§‹å†™ä½œç« èŠ‚: {task.section_title}")
        
        # 1. åŠ è½½æŒ‡æ ‡æ•°æ®
        try:
            # ä½¿ç”¨é›†ä¸­åçš„é€šç”¨JSONæå–å·¥å…·ï¼Œè¾“å‡ºå³ä¸ºå¯æ¶ˆè´¹ç»“æ„
            parsed = extract_json_from_llm_response(metric_table_json)

            if isinstance(parsed, list):
                metric_df = pd.DataFrame(parsed)
            elif isinstance(parsed, dict):
                metric_df = pd.DataFrame([parsed])
            else:
                metric_df = pd.DataFrame()
        except Exception as e:
            logger.error(f"è§£ææŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
            metric_df = pd.DataFrame()
        
        # 2. è·å–ç›¸å…³æŒ‡æ ‡æ•°æ®
        relevant_metrics = self._get_relevant_metrics(task, metric_df)
        
        # 3. RAGæ£€ç´¢äº‹å®ä¾æ® (ç®€åŒ–å®ç°)
        factual_basis = await self._retrieve_factual_basis(task, vector_store_path)
        
        # 4. æ„å»ºå†™ä½œprompt
        prompt = self._build_writing_prompt(task, factual_basis, relevant_metrics)
        
        # 5. ç”Ÿæˆç« èŠ‚å†…å®¹
        section_content = await self._generate_content(prompt)
        
        logger.info(f"ç« èŠ‚å†™ä½œå®Œæˆ: {task.section_title}")
        return section_content
    
    def _get_relevant_metrics(self, task: Task, metric_df: pd.DataFrame) -> pd.DataFrame:
        """è·å–ä¸ä»»åŠ¡ç›¸å…³çš„æŒ‡æ ‡æ•°æ®ï¼ˆåŠ¨æ€è§£è€¦åï¼Œé»˜è®¤è¿”å›å…¨éƒ¨æŒ‡æ ‡ï¼‰"""
        if metric_df.empty:
            return pd.DataFrame()
        return metric_df
    
    async def _retrieve_factual_basis(self, task: Task, vector_store_path: str) -> str:
        """ğŸ§  ä½¿ç”¨æ™ºèƒ½æ£€ç´¢æœåŠ¡æ£€ç´¢ç›¸å…³çš„äº‹å®ä¾æ®"""
        try:
            # ğŸ§  æ„å»ºæ›´æ™ºèƒ½çš„æ£€ç´¢æŸ¥è¯¢ - ç»“åˆç« èŠ‚æ ‡é¢˜å’Œå†™ä½œè¦æ±‚
            search_query = f"{task.section_title} {task.instruction[:200]}"
            
            # ğŸ§  æ£€ç´¢æ¨¡å¼é€‰æ‹©äº¤ç”±æ™ºèƒ½æ£€ç´¢æœåŠ¡æ ¹æ®é…ç½®å†³ç­–ï¼Œè¿™é‡Œç»Ÿä¸€èµ°hybrid
            search_result = await intelligent_search.intelligent_search(
                query=search_query,
                project_vector_storage_path=vector_store_path,
                mode="hybrid",
                enable_global=True,
                max_results=6
            )
            
            # æå–æ£€ç´¢åˆ°çš„å†…å®¹
            if search_result.get("results"):
                results = search_result["results"]
                factual_basis = "\n\n".join([
                    f"**ğŸ§  æ™ºèƒ½æ£€ç´¢èµ„æ–™{i+1}**: {result}" 
                    for i, result in enumerate(results[:6])  # å–å‰6ä¸ªæœ€ç›¸å…³çš„ç»“æœ
                ])
                
                # ğŸ§  æ·»åŠ æ™ºèƒ½æ´å¯Ÿ
                if search_result.get("insights"):
                    factual_basis += "\n\n**ğŸ’¡ æ™ºèƒ½åˆ†ææ´å¯Ÿ**:\n" + "\n".join(search_result["insights"])
                
                logger.info(f"ğŸ§  æ™ºèƒ½æ£€ç´¢åˆ° {len(results)} æ¡ç›¸å…³ä¿¡æ¯ç”¨äºç« èŠ‚: {task.section_title}ï¼Œä½¿ç”¨æ¨¡å¼: {search_result.get('mode_used', 'hybrid')}")
                return factual_basis
            else:
                logger.warning(f"æœªæ£€ç´¢åˆ°ç»“æœ: {task.section_title}")
                return f"æœªèƒ½æ£€ç´¢åˆ°å…³äº'{task.section_title}'çš„ç›¸å…³ä¿¡æ¯ã€‚"
            
        except Exception as e:
            logger.error(f"å‘é‡æ£€ç´¢å¤±è´¥: {e}")
            return f"å‘é‡æ£€ç´¢å‘ç”Ÿé”™è¯¯ï¼Œæ— æ³•è·å–å…³äº'{task.section_title}'çš„äº‹å®ä¾æ®ã€‚é”™è¯¯: {str(e)}"
    
    def _build_writing_prompt(self, task: Task, factual_basis: str, relevant_metrics: pd.DataFrame) -> str:
        """æ„å»ºå†™ä½œprompt - æ•´åˆArchitectçš„å†™ä½œæŒ‡å¯¼"""
        
        # æ ¼å¼åŒ–æŒ‡æ ‡æ•°æ®
        metrics_text = ""
        if not relevant_metrics.empty:
            # æ£€æŸ¥DataFrameçš„åˆ—ç»“æ„
            if 'name' in relevant_metrics.columns:
                # æ–°æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨æŒ‡æ ‡ä¿¡æ¯
                metrics_text = "\n".join([
                    f"- **{row['name']}** ({row.get('category', 'æœªåˆ†ç±»')}): {row.get('è¯„åˆ†è§„åˆ™', 'è¯„åˆ†è§„åˆ™å¾…è¡¥å……')}"
                    for _, row in relevant_metrics.iterrows()
                ])
            else:
                # æ—§æ ¼å¼å…¼å®¹
                metrics_text = "\n".join([
                    f"- {row.get('name', 'æœªçŸ¥æŒ‡æ ‡')}: {row.get('value', 'æ•°å€¼å¾…è¡¥å……')} ({row.get('analysis', 'åˆ†æå¾…è¡¥å……')})"
                    for _, row in relevant_metrics.iterrows()
                ])
        
        prompt = ENV_SECTION_WRITING_PROMPT.format(
            section_title=task.section_title,
            instruction=task.instruction,
            factual_basis=factual_basis,
            metrics_text=metrics_text,
            word_limit="2000"
        )
        return prompt
    
    async def _generate_content(self, prompt: str) -> str:
        """ç”Ÿæˆç« èŠ‚å†…å®¹"""
        # ä½¿ç”¨LLMç”Ÿæˆå†…å®¹
        # æ³¨å…¥é¡¹ç›®é…ç½®ä¿¡æ¯ä½œä¸ºç³»ç»Ÿçº§æç¤º
        project_info_text = get_project_info_text()
        section_content = await self._aask(prompt, [ENV_WRITER_BASE_SYSTEM, project_info_text])
        return section_content


