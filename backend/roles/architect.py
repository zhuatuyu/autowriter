#!/usr/bin/env python
"""
æ¶æ„å¸ˆè§’è‰² - æŠ¥å‘Šç»“æ„è®¾è®¡å’ŒæŒ‡æ ‡åˆ†æ
"""
from metagpt.actions.design_api import WriteDesign
from metagpt.roles import Role  # æ”¹ä¸ºç»§æ‰¿Roleè€Œä¸æ˜¯RoleZero
from metagpt.schema import Message
from metagpt.logs import logger

from backend.actions.research_action import ConductComprehensiveResearch, ResearchData
from backend.actions.architect_action import DesignReportStructure as ArchitectAction, ArchitectOutput
from typing import List, Optional
import re

class Architect(Role):
    """
    Represents an Architect role in a software development process.
    """

    name: str = "Bob"
    profile: str = "Architect"
    goal: str = "Design a concise, usable, complete software system"
    constraints: str = "Try to specify good open source tools as much as possible"

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # è®¾ç½®Actionå’Œç›‘å¬ - ä¸“æ³¨äºæ¶ˆè´¹ProductManagerçš„ç ”ç©¶æˆæœ
        self.set_actions([ArchitectAction])
        self._watch([ConductComprehensiveResearch])  # ç›‘å¬ProductManagerçš„è¾“å‡º
        
        # ç”¨äºå­˜å‚¨å‘é‡çŸ¥è¯†åº“çš„å¼•ç”¨
        self._current_research_data: Optional[ResearchData] = None

    def _semantic_search(self, query: str, research_data: ResearchData, top_k: int = 3) -> List[str]:
        """
        åŸºäºè¯­ä¹‰çš„å‘é‡æ£€ç´¢ï¼ˆç›®å‰ä½¿ç”¨å…³é”®è¯åŒ¹é…ï¼Œåç»­å¯å‡çº§ä¸ºçœŸæ­£çš„å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ï¼‰
        """
        if not research_data.content_chunks:
            logger.warning("å‘é‡çŸ¥è¯†åº“ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œæ£€ç´¢")
            return []
        
        # æå–æŸ¥è¯¢å…³é”®è¯
        query_keywords = self._extract_keywords(query)
        logger.info(f"ğŸ” æ£€ç´¢å…³é”®è¯: {query_keywords}")
        
        # è®¡ç®—æ¯ä¸ªå†…å®¹å—çš„ç›¸å…³åº¦åˆ†æ•°
        chunk_scores = []
        for i, chunk in enumerate(research_data.content_chunks):
            score = self._calculate_relevance_score(chunk, query_keywords)
            chunk_scores.append((i, score, chunk))
        
        # æŒ‰åˆ†æ•°é™åºæ’åºï¼Œå–å‰top_kä¸ª
        chunk_scores.sort(key=lambda x: x[1], reverse=True)
        relevant_chunks = []
        
        for i, (chunk_idx, score, chunk) in enumerate(chunk_scores[:top_k]):
            if score > 0:  # åªè¿”å›æœ‰ç›¸å…³æ€§çš„å—
                relevant_chunks.append(chunk)
                logger.info(f"ğŸ“‹ ç›¸å…³å— {i+1} (åˆ†æ•°: {score}): {chunk[:100]}...")
        
        return relevant_chunks
    
    def _extract_keywords(self, query: str) -> List[str]:
        """æå–æŸ¥è¯¢ä¸­çš„å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼Œå»æ‰å¸¸è§åœç”¨è¯
        stopwords = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'å’Œ', 'ä¸', 'æˆ–', 'ä»¥åŠ', 'å¯¹äº', 'å…³äº', 'å¦‚ä½•', 'ä»€ä¹ˆ', 'å“ªäº›'}
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', query)
        keywords = [word for word in words if len(word) > 1 and word not in stopwords]
        return keywords
    
    def _calculate_relevance_score(self, chunk: str, keywords: List[str]) -> float:
        """è®¡ç®—å†…å®¹å—ä¸å…³é”®è¯çš„ç›¸å…³åº¦åˆ†æ•°"""
        score = 0
        chunk_lower = chunk.lower()
        
        for keyword in keywords:
            keyword_lower = keyword.lower()
            # ç²¾ç¡®åŒ¹é…å¾—åˆ†æ›´é«˜
            if keyword_lower in chunk_lower:
                count = chunk_lower.count(keyword_lower)
                score += count * 2  # å‡ºç°æ¬¡æ•°è¶Šå¤šåˆ†æ•°è¶Šé«˜
        
        # æ ‡å‡†åŒ–åˆ†æ•°
        return score / max(len(chunk), 1)

    async def _act(self) -> Message:
        """æ‰§è¡Œæ¶æ„è®¾è®¡ä»»åŠ¡"""
        logger.info(f"ğŸ—ï¸ {self.name} (Architect) å¼€å§‹æ‰§è¡Œæ¶æ„è®¾è®¡ä»»åŠ¡...")
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        memories = self.get_memories()
        logger.info(f"ğŸ“ Architect æ£€æŸ¥åˆ° {len(memories)} æ¡æ¶ˆæ¯å†å²")
        for i, msg in enumerate(memories):
            logger.info(f"  æ¶ˆæ¯ {i}: cause_by={msg.cause_by}, role={msg.role}")
        
        
        # è·å–ProductManagerçš„ç ”ç©¶æ•°æ® - å®Œæ•´è·å–åŒ…æ‹¬å‘é‡çŸ¥è¯†åº“
        research_data_obj = None
        research_brief = ""
        
        for msg in self.get_memories():
            logger.info(f"ğŸ” æ£€æŸ¥æ¶ˆæ¯: cause_by={msg.cause_by}, ç±»å‹={type(msg.cause_by)}")
            if str(msg.cause_by).endswith("ConductComprehensiveResearch"):
                logger.info(f"âœ… æ‰¾åˆ°åŒ¹é…çš„ProductManageræ¶ˆæ¯!")
                # æ­£ç¡®è§£æinstruct_contentä¸­çš„ResearchDataå¯¹è±¡
                if hasattr(msg, 'instruct_content') and msg.instruct_content:
                    try:
                        # ä¼˜å…ˆå¤„ç†ResearchDataå¯¹è±¡
                        if isinstance(msg.instruct_content, ResearchData):
                            research_data_obj = msg.instruct_content
                            research_brief = research_data_obj.brief
                            self._current_research_data = research_data_obj
                            logger.info(f"ğŸ“Š è·å–åˆ°å®Œæ•´ResearchDataï¼ŒåŒ…å« {len(research_data_obj.content_chunks)} ä¸ªå‘é‡å—")
                        elif hasattr(msg.instruct_content, 'brief'):
                            research_brief = msg.instruct_content.brief
                            # å°è¯•æ„é€ ResearchDataå¯¹è±¡
                            if hasattr(msg.instruct_content, 'content_chunks'):
                                research_data_obj = msg.instruct_content
                                self._current_research_data = research_data_obj
                        elif isinstance(msg.instruct_content, dict):
                            research_brief = msg.instruct_content.get('brief', '')
                            # å°è¯•ä»å­—å…¸æ„é€ ResearchData
                            if 'content_chunks' in msg.instruct_content:
                                research_data_obj = ResearchData(**msg.instruct_content)
                                self._current_research_data = research_data_obj
                        else:
                            # å¦‚æœinstruct_contentä¸æ˜¯é¢„æœŸæ ¼å¼ï¼Œå°è¯•ä»contentè·å–
                            research_brief = msg.content
                    except Exception as e:
                        logger.error(f"è§£æç ”ç©¶æ•°æ®å¤±è´¥: {e}")
                        research_brief = msg.content
                break
        
        if not research_brief:
            logger.error("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç ”ç©¶æ•°æ®ï¼æ— æ³•è¿›è¡Œæ¶æ„è®¾è®¡")
            raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç ”ç©¶æ•°æ®ï¼Œæ— æ³•è¿›è¡Œæ¶æ„è®¾è®¡ã€‚è¯·ç¡®ä¿ProductManagerå·²å®Œæˆç ”ç©¶")
        
        logger.info(f"ğŸ“„ æˆåŠŸè·å–ç ”ç©¶ç®€æŠ¥ï¼Œé•¿åº¦: {len(research_brief)} å­—ç¬¦")
        if self._current_research_data:
            logger.info(f"ğŸ§  å‘é‡çŸ¥è¯†åº“å¯ç”¨ï¼ŒåŒ…å« {len(self._current_research_data.content_chunks)} ä¸ªå†…å®¹å—")
        
        # æ‰§è¡ŒæŠ¥å‘Šç»“æ„è®¾è®¡ - åˆ©ç”¨å‘é‡æ£€ç´¢å¢å¼ºè®¾è®¡
        todo = self.rc.todo
        if isinstance(todo, ArchitectAction):
            # ã€æ–°å¢ã€‘å¦‚æœæœ‰å‘é‡çŸ¥è¯†åº“ï¼Œè¿›è¡ŒRAGå¢å¼ºè®¾è®¡
            enhanced_research_context = research_brief
            
            if self._current_research_data and self._current_research_data.content_chunks:
                logger.info("ğŸ” å¯åŠ¨RAGå¢å¼ºçš„æŠ¥å‘Šç»“æ„è®¾è®¡...")
                
                # é’ˆå¯¹æŠ¥å‘Šç»“æ„è®¾è®¡è¿›è¡Œå¤šè§’åº¦æ£€ç´¢
                design_queries = [
                    "æŠ¥å‘Šç»“æ„ ç« èŠ‚åˆ’åˆ† ç›®å½•å¤§çº²",
                    "å…³é”®æŒ‡æ ‡ è¯„ä»·æŒ‡æ ‡ ç»©æ•ˆæŒ‡æ ‡",
                    "æ•°æ®åˆ†æ æŠ€æœ¯æ–¹æ¡ˆ å®æ–½æ–¹æ³•",
                    "é£é™©æŒ‘æˆ˜ é—®é¢˜å»ºè®® è§£å†³æ–¹æ¡ˆ"
                ]
                
                rag_context = "\n\n### RAGæ£€ç´¢å¢å¼ºå†…å®¹\n\n"
                
                for i, query in enumerate(design_queries, 1):
                    relevant_chunks = self._semantic_search(query, self._current_research_data, top_k=2)
                    if relevant_chunks:
                        rag_context += f"#### æ£€ç´¢ç»´åº¦ {i}: {query}\n"
                        for j, chunk in enumerate(relevant_chunks, 1):
                            rag_context += f"**ç›¸å…³å†…å®¹ {j}:**\n{chunk}\n\n"
                
                # å°†RAGæ£€ç´¢ç»“æœä¸åŸå§‹ç ”ç©¶ç®€æŠ¥ç»“åˆ
                enhanced_research_context = research_brief + rag_context
                logger.info(f"âœ… RAGå¢å¼ºå®Œæˆï¼Œå¢å¼ºåå†…å®¹é•¿åº¦: {len(enhanced_research_context)} å­—ç¬¦")
            
            # DesignReportStructureè¿”å›Tuple[ReportStructure, MetricAnalysisTable]
            # ä¼ é€’research_dataå‚æ•°åˆ°æ–°çš„Action
            report_structure, metric_table = await todo.run(enhanced_research_context, research_data=self._current_research_data)
            
            # ä¿å­˜ReportStructureåˆ°æ–‡ä»¶
            if hasattr(self, '_project_repo') and self._project_repo:
                try:
                    # ä¿å­˜æŠ¥å‘Šç»“æ„
                    structure_content = f"# æŠ¥å‘Šç»“æ„è®¾è®¡\n\n## æŠ¥å‘Šæ ‡é¢˜\n{report_structure.title}\n\n"
                    structure_content += "## ç« èŠ‚ç»“æ„\n\n"
                    for i, section in enumerate(report_structure.sections, 1):
                        structure_content += f"### {i}. {section.section_title}\n"
                        structure_content += f"**å…³è”æŒ‡æ ‡**: {', '.join(section.metric_ids)}\n"
                        structure_content += f"**å†™ä½œè¦ç‚¹**: {section.description_prompt}\n\n"
                    
                    await self._project_repo.docs.save(
                        filename="report_structure.md", 
                        content=structure_content
                    )
                    logger.info(f"æŠ¥å‘Šç»“æ„å·²ä¿å­˜åˆ°: {self._project_repo.docs.workdir}/report_structure.md")
                    
                    # ä¿å­˜æŒ‡æ ‡åˆ†æè¡¨
                    import json
                    metric_data = json.loads(metric_table.data_json)
                    metric_content = f"# æŒ‡æ ‡åˆ†æè¡¨\n\n```json\n{json.dumps(metric_data, ensure_ascii=False, indent=2)}\n```"
                    
                    await self._project_repo.docs.save(
                        filename="metric_analysis_table.md", 
                        content=metric_content
                    )
                    logger.info(f"æŒ‡æ ‡åˆ†æè¡¨å·²ä¿å­˜åˆ°: {self._project_repo.docs.workdir}/metric_analysis_table.md")
                    
                except Exception as e:
                    logger.error(f"ä¿å­˜Architectè¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
            
            # åˆ›å»ºåŒ…å«ReportStructureçš„æ¶ˆæ¯ï¼Œä¾›ProjectManagerä½¿ç”¨
            # åˆ›å»ºå¤åˆè¾“å‡ºå¯¹è±¡ï¼ŒæŒ‰ç…§åŸç”ŸMetaGPTæ¨¡å¼
            architect_output = ArchitectOutput(
                report_structure=report_structure,
                metric_analysis_table=metric_table
            )
            
            # è¾“å‡ºæ›´è¯¦ç»†çš„å®Œæˆä¿¡æ¯
            content_msg = f"ğŸ“‹ æŠ¥å‘Šç»“æ„è®¾è®¡å®Œæˆï¼š{report_structure.title}ï¼Œå…±{len(report_structure.sections)}ä¸ªç« èŠ‚"
            if self._current_research_data:
                content_msg += f"ï¼›âœ¨ ä½¿ç”¨RAGå¢å¼ºè®¾è®¡ï¼ˆåŸºäº{len(self._current_research_data.content_chunks)}ä¸ªå‘é‡å—ï¼‰"
            content_msg += "ï¼›ğŸ“Š æŒ‡æ ‡åˆ†æè¡¨ç”Ÿæˆå®Œæˆ"
            
            msg = Message(
                content=content_msg,
                role=self.profile,
                cause_by=type(todo),
                sent_from=self,
                instruct_content=architect_output  # ç›´æ¥ä¼ é€’Pydanticå¯¹è±¡ï¼ŒåƒåŸç”Ÿä»£ç ä¸€æ ·
            )
            
            self.rc.memory.add(msg)
            return msg
        else:
            # å¦‚æœä¸æ˜¯DesignReportStructureï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
            result = await todo.run(research_brief)
            
            msg = Message(
                content=result,
                role=self.profile,
                cause_by=type(todo),
                sent_from=self,
            )
            
            self.rc.memory.add(msg)
            return msg