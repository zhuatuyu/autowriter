#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆå…¨å±€çŸ¥è¯†åº“è®¾ç½®å·¥å…·
ä¸“é—¨ç”¨äºæ·»åŠ å›½å®¶çº§æ–‡æ¡£ï¼ˆa1.md, a2.mdï¼‰åˆ°å…¨å±€çŸ¥è¯†åº“å¹¶æµ‹è¯•
"""

import asyncio
import sys
import shutil
from pathlib import Path

# ç¡®ä¿èƒ½å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
sys.path.append('.')

from backend.services.global_knowledge import global_knowledge
from backend.services.hybrid_search import hybrid_search


async def setup_national_documents():
    """è®¾ç½®å›½å®¶çº§æ–‡æ¡£åˆ°å…¨å±€çŸ¥è¯†åº“"""
    
    print("ğŸ‡¨ğŸ‡³ å¼€å§‹è®¾ç½®å›½å®¶çº§çŸ¥è¯†æ–‡æ¡£...")
    
    # ç¡®ä¿å…¨å±€å­˜å‚¨ç›®å½•å­˜åœ¨
    global_storage = Path("workspace/vector_storage/global")
    laws_dir = global_storage / "laws"
    laws_dir.mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶a1.mdå’Œa2.mdåˆ°å…¨å±€çŸ¥è¯†åº“
    source_files = ["a1.md", "a2.md"]
    copied_files = []
    
    for source_file in source_files:
        source_path = Path(source_file)
        if source_path.exists():
            target_path = laws_dir / source_path.name
            shutil.copy2(source_path, target_path)
            copied_files.append(str(target_path))
            print(f"âœ… å·²å¤åˆ¶: {source_file} â†’ {target_path}")
        else:
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {source_file}")
    
    if not copied_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è¦æ·»åŠ çš„æ–‡ä»¶!")
        return False
    
    print(f"\nğŸ“Š å…¨å±€çŸ¥è¯†åº“ç»Ÿè®¡:")
    stats = global_knowledge.get_global_stats()
    print(f"  æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
    print(f"  å­˜å‚¨è·¯å¾„: {stats['storage_path']}")
    
    # å¼ºåˆ¶é‡æ–°æ„å»ºç´¢å¼•
    print("\nğŸ”§ å¼€å§‹æ„å»ºå…¨å±€çŸ¥è¯†åº“ç´¢å¼•...")
    success = await global_knowledge.build_global_index(force_rebuild=True)
    
    if success:
        print("âœ… å…¨å±€çŸ¥è¯†åº“ç´¢å¼•æ„å»ºæˆåŠŸ!")
        return True
    else:
        print("âŒ å…¨å±€çŸ¥è¯†åº“ç´¢å¼•æ„å»ºå¤±è´¥!")
        return False


async def test_global_search():
    """æµ‹è¯•å…¨å±€çŸ¥è¯†åº“æœç´¢åŠŸèƒ½"""
    
    print("\nğŸ” æµ‹è¯•å…¨å±€çŸ¥è¯†åº“æœç´¢åŠŸèƒ½...")
    
    test_queries = [
        "é¢„ç®—æ³•",
        "ç»©æ•ˆè¯„ä»·",
        "è´¢æ”¿ç®¡ç†",
        "é¡¹ç›®è¯„ä»·æŒ‡æ ‡"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” æœç´¢: {query}")
        results = await global_knowledge.search_global(query, top_k=2)
        
        if results:
            print(f"âœ… æ‰¾åˆ° {len(results)} æ¡ç»“æœ:")
            for i, result in enumerate(results, 1):
                # æ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
                preview = result[:100].replace('\n', ' ').strip()
                print(f"  {i}. {preview}...")
        else:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")


async def test_hybrid_search():
    """æµ‹è¯•æ··åˆæ£€ç´¢åŠŸèƒ½"""
    
    print("\nğŸ” æµ‹è¯•æ··åˆæ£€ç´¢åŠŸèƒ½...")
    
    # åˆ›å»ºä¸€ä¸ªæµ‹è¯•é¡¹ç›®ç›®å½•
    test_project_dir = Path("workspace/test_project")
    test_vector_storage = test_project_dir / "vector_storage"
    test_vector_storage.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºæµ‹è¯•é¡¹ç›®æ–‡æ¡£
    test_doc = test_vector_storage / "é¡¹ç›®æ–‡æ¡£.md"
    test_doc.write_text("""
# æµ‹è¯•é¡¹ç›®æ–‡æ¡£

## é¡¹ç›®æ¦‚å†µ
è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é¡¹ç›®ï¼Œç”¨äºéªŒè¯æ··åˆæ£€ç´¢åŠŸèƒ½ã€‚

## é¢„ç®—ä¿¡æ¯
é¡¹ç›®æ€»é¢„ç®—ï¼š100ä¸‡å…ƒ
èµ„é‡‘æ¥æºï¼šè´¢æ”¿æ‹¨æ¬¾

## å®æ–½è®¡åˆ’
æŒ‰ç…§å›½å®¶ç›¸å…³æ³•å¾‹æ³•è§„æ‰§è¡Œï¼Œä¸¥æ ¼éµå®ˆé¢„ç®—æ³•è¦æ±‚ã€‚
""", encoding='utf-8')
    
    print(f"ğŸ“„ åˆ›å»ºæµ‹è¯•é¡¹ç›®æ–‡æ¡£: {test_doc}")
    
    # æµ‹è¯•æ··åˆæ£€ç´¢
    test_query = "é¢„ç®—æ³•è¦æ±‚"
    print(f"\nğŸ” æ··åˆæ£€ç´¢æµ‹è¯•: {test_query}")
    
    results = await hybrid_search.hybrid_search(
        query=test_query,
        project_vector_storage_path=str(test_vector_storage),
        enable_global=True,
        global_top_k=2,
        project_top_k=2
    )
    
    if results:
        print(f"âœ… æ··åˆæ£€ç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(results)} æ¡ç»“æœ:")
        for i, result in enumerate(results, 1):
            preview = result[:150].replace('\n', ' ').strip()
            print(f"  {i}. {preview}...")
    else:
        print("âŒ æ··åˆæ£€ç´¢æœªæ‰¾åˆ°ç»“æœ")
    
    # æ¸…ç†æµ‹è¯•ç›®å½•
    shutil.rmtree(test_project_dir, ignore_errors=True)
    print("ğŸ—‘ï¸  å·²æ¸…ç†æµ‹è¯•ç›®å½•")


def show_final_stats():
    """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
    
    print("\nğŸ“Š æœ€ç»ˆå…¨å±€çŸ¥è¯†åº“ç»Ÿè®¡:")
    stats = global_knowledge.get_global_stats()
    
    print(f"  å­˜å‚¨è·¯å¾„: {stats['storage_path']}")
    print(f"  ç´¢å¼•è·¯å¾„: {stats['index_path']}")
    print(f"  ç´¢å¼•çŠ¶æ€: {'âœ… å·²æ„å»º' if stats['index_exists'] else 'âŒ æœªæ„å»º'}")
    print(f"  æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
    
    if stats['categories']:
        print("\nğŸ“ æ–‡æ¡£åˆ†ç±»ç»Ÿè®¡:")
        for category, count in stats['categories'].items():
            print(f"  {category}: {count} ä¸ªæ–‡ä»¶")


async def main():
    """ä¸»å‡½æ•°"""
    
    print("=" * 60)
    print("ğŸ›ï¸  å›½å®¶çº§çŸ¥è¯†åº“è®¾ç½®å·¥å…·")
    print("=" * 60)
    
    try:
        # 1. è®¾ç½®å›½å®¶çº§æ–‡æ¡£
        success = await setup_national_documents()
        if not success:
            print("âŒ è®¾ç½®å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
            return
        
        # 2. æµ‹è¯•å…¨å±€æœç´¢
        await test_global_search()
        
        # 3. æµ‹è¯•æ··åˆæ£€ç´¢
        await test_hybrid_search()
        
        # 4. æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        show_final_stats()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ å…¨å±€çŸ¥è¯†åº“è®¾ç½®å®Œæˆ!")
        print("ğŸ’¡ ç°åœ¨æ‰€æœ‰æ™ºèƒ½ä½“éƒ½å¯ä»¥åŒæ—¶ä½¿ç”¨:")
        print("   - ğŸŒ å…¨å±€çŸ¥è¯†åº“ (å›½å®¶æ³•è§„ã€æ ‡å‡†)")
        print("   - ğŸ“ é¡¹ç›®çŸ¥è¯†åº“ (é¡¹ç›®ç‰¹å®šæ–‡æ¡£)")
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())