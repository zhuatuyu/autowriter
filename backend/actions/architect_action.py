#!/usr/bin/env python
"""
æ¶æ„å¸ˆActioné›†åˆ - æŠ¥å‘Šç»“æ„è®¾è®¡å’ŒæŒ‡æ ‡åˆ†æ
é‡æ„å®ç°ä¸‰ç¯èŠ‚é€»è¾‘ï¼šåˆ†æç®€æŠ¥ -> RAGæ£€ç´¢ -> ç»¼åˆè®¾è®¡
"""
import pandas as pd
import json
import re
from typing import List, Tuple, Optional
from pydantic import BaseModel, Field
from metagpt.actions import Action
from metagpt.logs import logger
from backend.actions.research_action import ResearchData


# --- æ¶æ„å¸ˆä¸“ç”¨æç¤ºè¯æ¨¡æ¿ ---
ARCHITECT_BASE_SYSTEM = """ä½ æ˜¯ç»©æ•ˆè¯„ä»·æŠ¥å‘Šçš„æ¶æ„å¸ˆã€‚ä½ çš„ç›®æ ‡æ˜¯ï¼š
1. æ·±å…¥åˆ†æç ”ç©¶ç®€æŠ¥ï¼Œæå–é¡¹ç›®æ ¸å¿ƒä¿¡æ¯
2. åŸºäºæ ‡å‡†ç»©æ•ˆè¯„ä»·æ¡†æ¶è®¾è®¡æŠ¥å‘Šç»“æ„
3. æ„å»ºç§‘å­¦çš„æŒ‡æ ‡ä½“ç³»ï¼Œç¡®ä¿è¯„ä»·çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§
"""

PROJECT_INFO_EXTRACTION_PROMPT = """ä½ æ˜¯ç»©æ•ˆè¯„ä»·æŠ¥å‘Šçš„æ¶æ„å¸ˆã€‚è¯·ä»ä»¥ä¸‹ç ”ç©¶ç®€æŠ¥ä¸­æå–é¡¹ç›®çš„æ ¸å¿ƒä¿¡æ¯ï¼Œç”¨äºåç»­åŸºäºæ ‡å‡†æ¨¡æ¿çš„æŠ¥å‘Šç»“æ„è®¾è®¡ã€‚

ç ”ç©¶ç®€æŠ¥ï¼š
{research_brief}

è¯·è¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
1. project_name: é¡¹ç›®å…¨ç§°
2. project_type: é¡¹ç›®ç±»å‹ï¼ˆå¦‚ï¼šè´¢æ”¿æ”¯å‡ºé¡¹ç›®ã€ä¸“é¡¹èµ„é‡‘é¡¹ç›®ç­‰ï¼‰
3. budget_amount: é¡¹ç›®é¢„ç®—é‡‘é¢ï¼ˆå¦‚æœæœ‰ï¼‰
4. implementation_period: å®æ–½æœŸé—´
5. target_beneficiaries: ä¸»è¦å—ç›Šå¯¹è±¡
6. main_objectives: ä¸»è¦ç›®æ ‡ï¼ˆåˆ—è¡¨å½¢å¼ï¼‰
7. key_activities: ä¸»è¦æ´»åŠ¨å†…å®¹ï¼ˆåˆ—è¡¨å½¢å¼ï¼‰
8. performance_focus: ç»©æ•ˆé‡ç‚¹å…³æ³¨é¢†åŸŸï¼ˆå¦‚ï¼šç»æµæ•ˆç›Šã€ç¤¾ä¼šæ•ˆç›Šã€ç”Ÿæ€æ•ˆç›Šç­‰ï¼‰

è¦æ±‚ï¼š
- ä¿¡æ¯è¦å‡†ç¡®ã€å®Œæ•´
- å¦‚æœæŸäº›ä¿¡æ¯ä¸æ˜ç¡®ï¼Œæ ‡æ³¨ä¸º"å¾…è¡¥å……"
- é‡ç‚¹å…³æ³¨ä¸ç»©æ•ˆè¯„ä»·ç›¸å…³çš„ä¿¡æ¯
"""

RAG_KEYWORDS_GENERATION_PROMPT = """ä½ æ˜¯æ¶æ„å¸ˆçš„RAGæ£€ç´¢åŠ©æ‰‹ã€‚åŸºäºä»¥ä¸‹é¡¹ç›®ä¿¡æ¯ï¼Œç”Ÿæˆç”¨äºæ£€ç´¢å‘é‡çŸ¥è¯†åº“çš„å…³é”®è¯ç»„ã€‚

é¡¹ç›®ä¿¡æ¯ï¼š
{project_info}

è¯·ç”Ÿæˆ6ä¸ªç±»åˆ«çš„æ£€ç´¢å…³é”®è¯ï¼Œæ¯ä¸ªç±»åˆ«åŒ…å«3-5ä¸ªå…·ä½“çš„æ£€ç´¢è¯ï¼š

è¿”å›JSONæ ¼å¼ï¼š
[
  {{
    "category": "é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡",
    "keywords": ["é¡¹ç›®ç«‹é¡¹èƒŒæ™¯", "ä¸»è¦ç›®æ ‡", "é¢„æœŸæˆæœ"]
  }},
  {{
    "category": "èµ„é‡‘ä¸é¢„ç®—",
    "keywords": ["é¢„ç®—æ€»é¢", "èµ„é‡‘æ¥æº", "èµ„é‡‘åˆ†é…"]
  }},
  {{
    "category": "å®æ–½æ–¹æ¡ˆ",
    "keywords": ["å®æ–½æ­¥éª¤", "æŠ€æœ¯æ–¹æ¡ˆ", "ç®¡ç†æªæ–½"]
  }},
  {{
    "category": "æ•ˆæœä¸æˆæ•ˆ",
    "keywords": ["å®æ–½æ•ˆæœ", "äº§å‡ºæŒ‡æ ‡", "æ•ˆç›Šåˆ†æ"]
  }},
  {{
    "category": "æ”¿ç­–ä¾æ®",
    "keywords": ["æ”¿ç­–æ–‡ä»¶", "æ³•è§„ä¾æ®", "æ ‡å‡†è§„èŒƒ"]
  }},
  {{
    "category": "é£é™©ä¸æŒ‘æˆ˜",
    "keywords": ["å­˜åœ¨é—®é¢˜", "é£é™©å› ç´ ", "æ”¹è¿›å»ºè®®"]
  }}
]

è¦æ±‚ï¼šå…³é”®è¯è¦å…·ä½“ã€å‡†ç¡®ï¼Œèƒ½åœ¨{project_name}ç›¸å…³èµ„æ–™ä¸­æ‰¾åˆ°å¯¹åº”ä¿¡æ¯ã€‚
"""

SECTION_PROMPT_GENERATION_TEMPLATE = """é’ˆå¯¹{project_name}ï¼Œ{base_prompt}

### ğŸ“‹ å…·ä½“å†™ä½œæŒ‡å¯¼ä¸æ£€ç´¢è¦æ±‚ï¼š

{rag_instructions}

### ğŸ” RAGæ£€ç´¢ç­–ç•¥ï¼š
å†™ä½œæ—¶è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š
1. é¦–å…ˆæ£€ç´¢ä¸Šè¿°å…³é”®ä¿¡æ¯é¡¹ï¼Œè·å–å…·ä½“æ•°æ®å’Œäº‹å®
2. åŸºäºæ£€ç´¢åˆ°çš„çœŸå®ä¿¡æ¯è¿›è¡Œåˆ†æå’Œè®ºè¿°
3. é¿å…æ³›æ³›è€Œè°ˆï¼Œç¡®ä¿æ¯ä¸ªè®ºç‚¹éƒ½æœ‰å…·ä½“çš„æ•°æ®æ”¯æ’‘
4. å¦‚æœæŸé¡¹ä¿¡æ¯æ£€ç´¢ä¸åˆ°ï¼Œæ˜ç¡®æ ‡æ³¨"ä¿¡æ¯å¾…è¡¥å……"

### ğŸ“Š è´¨é‡è¦æ±‚ï¼š
- æ•°æ®å‡†ç¡®ï¼šæ‰€æœ‰æ•°å­—ã€æ—¶é—´ã€åç§°å¿…é¡»æ¥è‡ªæ£€ç´¢åˆ°çš„åŸå§‹èµ„æ–™
- é€»è¾‘æ¸…æ™°ï¼šæŒ‰ç…§æ£€ç´¢æŒ‡å¯¼çš„é¡ºåºç»„ç»‡å†…å®¹ç»“æ„
- æ·±åº¦åˆ†æï¼šä¸ä»…è¦åˆ—å‡ºäº‹å®ï¼Œè¿˜è¦åˆ†æåŸå› å’Œå½±å“
"""

METRICS_DESIGN_PROMPT = """ä½ æ˜¯ç»©æ•ˆè¯„ä»·æŒ‡æ ‡ä½“ç³»çš„æ¶æ„å¸ˆã€‚è¯·åŸºäºä»¥ä¸‹é¡¹ç›®ä¿¡æ¯ï¼Œè®¾è®¡ä¸€å¥—å®Œæ•´çš„ç»©æ•ˆè¯„ä»·æŒ‡æ ‡ä½“ç³»ã€‚

é¡¹ç›®ä¿¡æ¯ï¼š
{project_info}

æŒ‡æ ‡ä½“ç³»è®¾è®¡è¦æ±‚ï¼š
1. ä¸€çº§æŒ‡æ ‡æƒé‡åˆ†é…ï¼šå†³ç­–(15åˆ†)ã€è¿‡ç¨‹(25åˆ†)ã€äº§å‡º(35åˆ†)ã€æ•ˆç›Š(25åˆ†)
2. æ¯ä¸ªä¸€çº§æŒ‡æ ‡ä¸‹è®¾ç½®2-3ä¸ªå…·ä½“æŒ‡æ ‡
3. æ¯ä¸ªæŒ‡æ ‡å¿…é¡»é€‰æ‹©ä¸€ç§è¯„ä»·ç±»å‹ï¼Œå…±6ç§å¯é€‰ï¼š
   - "è¦ç´ ç¬¦åˆåº¦è®¡åˆ†": æ ¹æ®ç¬¦åˆçš„è¦ç´ æ•°é‡è®¡åˆ†
   - "å…¬å¼è®¡ç®—å¾—åˆ†": é€šè¿‡æ•°å­¦å…¬å¼è®¡ç®—å¾—åˆ†  
   - "æ¡ä»¶åˆ¤æ–­å¾—åˆ†": æ ¹æ®æ˜¯å¦æ»¡è¶³æ¡ä»¶è®¡åˆ†
   - "å®šæ€§ä¸å®šé‡ç»“åˆ": ç»¼åˆå®šæ€§å’Œå®šé‡è¯„ä»·
   - "é€’å‡æ‰£åˆ†æœºåˆ¶": ä»æ»¡åˆ†å¼€å§‹æ ¹æ®é—®é¢˜æ‰£åˆ†
   - "æå…‹ç‰¹é‡è¡¨æ³•": é€šè¿‡æ»¡æ„åº¦è°ƒæŸ¥è®¡åˆ†

è¯·è¿”å›JSONæ ¼å¼ï¼Œæ¯ä¸ªæŒ‡æ ‡åŒ…å«ï¼š
- metric_id: å”¯ä¸€æ ‡è¯†ï¼ˆè‹±æ–‡ï¼‰
- name: æŒ‡æ ‡åç§°ï¼ˆä¸­æ–‡ï¼‰
- category: æŒ‡æ ‡åˆ†ç±»
- ä¸€çº§æŒ‡æ ‡: "å†³ç­–"/"è¿‡ç¨‹"/"äº§å‡º"/"æ•ˆç›Š"
- äºŒçº§æŒ‡æ ‡: å…·ä½“çš„äºŒçº§æŒ‡æ ‡åç§°
- ä¸‰çº§æŒ‡æ ‡: å…·ä½“çš„ä¸‰çº§æŒ‡æ ‡åç§°
- åˆ†å€¼: è¯¥æŒ‡æ ‡æƒé‡åˆ†å€¼ï¼ˆä¸ä¸€çº§æŒ‡æ ‡æƒé‡åŒ¹é…ï¼‰
- evaluation_type: è¯„ä»·ç±»å‹ï¼ˆå¿…é¡»é€‰æ‹©ä¸Šè¿°6ç§ä¹‹ä¸€ï¼‰
- evaluation_points: å…·ä½“è¯„ä»·è¦ç‚¹ï¼ˆæ•°ç»„æ ¼å¼ï¼Œå¦‚["â‘ ç«‹é¡¹ç¬¦åˆæ³•è§„","â‘¡ç¬¦åˆè§„åˆ’"]ï¼‰
- scoring_method: è¯¦ç»†è®¡åˆ†æ–¹å¼ï¼ˆå¦‚"å…·å¤‡ä¸€ä¸ªè¦ç´ å¾—20%åˆ†å€¼"ï¼‰
- è¯„åˆ†è¿‡ç¨‹: Writeræ‰§è¡Œè¯„ä»·çš„å…·ä½“æŒ‡å¯¼

âš ï¸ é‡è¦æ ¼å¼è¦æ±‚ï¼š
- æ‰€æœ‰å­—æ®µåå¿…é¡»ä½¿ç”¨è‹±æ–‡æˆ–ä¸­æ–‡ï¼Œä¸èƒ½æ··ç”¨
- scoring_methodå­—æ®µå¿…é¡»ä¸€è‡´ï¼Œä¸èƒ½ä½¿ç”¨"è¯„åˆ†æ–¹æ³•"æˆ–"scoringæ–¹æ³•"
- ç¡®ä¿JSONæ ¼å¼å®Œå…¨æ­£ç¡®ï¼Œæ‰€æœ‰å­—æ®µéƒ½æœ‰å€¼

æ ‡å‡†ç¤ºä¾‹ï¼š
[
  {{
    "metric_id": "policy_compliance",
    "name": "æ”¿ç­–åˆè§„æ€§",
    "category": "å†³ç­–æŒ‡æ ‡",
    "ä¸€çº§æŒ‡æ ‡": "å†³ç­–",
    "äºŒçº§æŒ‡æ ‡": "æ”¿ç­–ç¬¦åˆæ€§",
    "ä¸‰çº§æŒ‡æ ‡": "æ”¿ç­–åˆè§„ç‡",
    "åˆ†å€¼": 7.5,
    "evaluation_type": "è¦ç´ ç¬¦åˆåº¦è®¡åˆ†",
    "evaluation_points": [
      "â‘ é¡¹ç›®ç«‹é¡¹ç¬¦åˆå›½å®¶æ³•å¾‹æ³•è§„ã€å›½æ°‘ç»æµå‘å±•è§„åˆ’å’Œç›¸å…³æ”¿ç­–",
      "â‘¡é¡¹ç›®ç«‹é¡¹ç¬¦åˆè¡Œä¸šå‘å±•è§„åˆ’å’Œæ”¿ç­–è¦æ±‚",
      "â‘¢é¡¹ç›®ç«‹é¡¹ä¸éƒ¨é—¨èŒè´£èŒƒå›´ç›¸ç¬¦ï¼Œå±äºéƒ¨é—¨å±¥èŒæ‰€éœ€",
      "â‘£é¡¹ç›®å±äºå…¬å…±è´¢æ”¿æ”¯æŒèŒƒå›´ï¼Œç¬¦åˆä¸­å¤®ã€åœ°æ–¹äº‹æƒæ”¯å‡ºè´£ä»»åˆ’åˆ†åŸåˆ™",
      "â‘¤è¯¥é¡¹ç›®ä¸ç›¸å…³éƒ¨é—¨åŒç±»é¡¹ç›®æˆ–è€…éƒ¨é—¨å†…éƒ¨ç›¸å…³é¡¹ç›®æ— äº¤å‰é‡å¤"
    ],
    "scoring_method": "å…·å¤‡ä¸€ä¸ªå¾—åˆ†è¦ç´ ï¼Œå¾—åˆ°æŒ‡æ ‡åˆ†å€¼çš„20%",
    "è¯„åˆ†è¿‡ç¨‹": "Writeréœ€æ ¸å¯¹é¡¹ç›®æ–‡ä»¶ä¸å›½å®¶ã€åœ°æ–¹æ”¿åºœæ”¿ç­–çš„åŒ¹é…ç¨‹åº¦ï¼Œæ£€æŸ¥ç›¸å…³æ³•å¾‹æ³•è§„å¼•ç”¨æƒ…å†µåŠæ”¿ç­–ä¾æ®ææ–™ï¼Œå¯¹ç…§è¯„ä»·è¦ç‚¹é€ä¸€åˆ¤æ–­ç¬¦åˆæƒ…å†µ"
  }}
]

è¯·ä¸º{project_name}ï¼ˆ{project_type}ï¼‰è®¾è®¡8-12ä¸ªæŒ‡æ ‡ï¼Œç¡®ä¿ï¼š
- å†³ç­–ç±»æŒ‡æ ‡æ€»åˆ†å€¼=15åˆ†
- è¿‡ç¨‹ç±»æŒ‡æ ‡æ€»åˆ†å€¼=25åˆ†  
- äº§å‡ºç±»æŒ‡æ ‡æ€»åˆ†å€¼=35åˆ†
- æ•ˆç›Šç±»æŒ‡æ ‡æ€»åˆ†å€¼=25åˆ†
- æ¯ä¸ªæŒ‡æ ‡éƒ½æœ‰æ˜ç¡®çš„è¯„ä»·ç±»å‹å’Œè¯¦ç»†è¯„ä»·è¦ç‚¹
"""

# 6ç§æ ‡å‡†åŒ–è¯„ä»·ç±»å‹å®šä¹‰
EVALUATION_TYPES = {
    "è¦ç´ ç¬¦åˆåº¦è®¡åˆ†": {
        "description": "æ ¹æ®å„é¡¹è¦ç´ çš„ç¬¦åˆæƒ…å†µè¿›è¡Œè®¡åˆ†",
        "scoring_guidance": """è¦ç´ ç¬¦åˆåº¦è®¡åˆ†è®¡ç®—æ­¥éª¤ï¼š
1. ä»äº‹å®ä¸­è¯†åˆ«ç¬¦åˆçš„è¦ç´ ï¼ˆå¦‚"ç¬¦åˆè¯„ä»·è¦ç‚¹â‘ â‘¡"ï¼‰
2. ä»è§„åˆ™ä¸­æå–æ¯ä¸ªè¦ç´ çš„åˆ†å€¼
3. å°†ç¬¦åˆè¦ç´ çš„åˆ†å€¼ç›¸åŠ å¾—åˆ°æœ€ç»ˆå¾—åˆ†

ç¤ºä¾‹ï¼šäº‹å®"ç¬¦åˆâ‘ â‘¡ï¼Œä¸ç¬¦åˆâ‘¢"ï¼Œè§„åˆ™"â‘ â‘¡å„30%ï¼Œâ‘¢40%"
è®¡ç®—ï¼š30+30+0=60åˆ†""",
        "opinion_requirements": """- å¿…é¡»åŒ…å«å…·ä½“çš„æ³•è§„å¼•ç”¨ã€æ–‡ä»¶åç§°ç­‰è¯¦å®å†…å®¹
- æ˜ç¡®åˆ—å‡ºæ¯ä¸ªè¯„ä»·è¦ç‚¹çš„ç¬¦åˆ/ä¸ç¬¦åˆæƒ…å†µ
- ä½¿ç”¨åˆ†å·åˆ†éš”å„è¦ç‚¹çš„è¯„ä»·
- ä¸å¾—åŒ…å«ä»»ä½•æœ€ç»ˆå¾—åˆ†æˆ–ç»“è®ºæ€§è¯­å¥"""
    },
    
    "å…¬å¼è®¡ç®—å¾—åˆ†": {
        "description": "é€šè¿‡ç‰¹å®šå…¬å¼è®¡ç®—å¾—å‡ºåˆ†æ•°",
        "scoring_guidance": """å…¬å¼è®¡ç®—å¾—åˆ†æ­¥éª¤ï¼š
1. ä»è§„åˆ™ä¸­æ‰¾åˆ°è®¡ç®—å…¬å¼
2. ä»äº‹å®ä¸­æå–æ•°å€¼
3. ä»£å…¥å…¬å¼è®¡ç®—ï¼Œç»“æœæ¢ç®—åˆ°100åˆ†åˆ¶

ç¤ºä¾‹ï¼šé¢„ç®—æ‰§è¡Œç‡=å®é™…æ”¯å‡º/é¢„ç®—é‡‘é¢Ã—100%
å®é™…æ”¯å‡º800ä¸‡ï¼Œé¢„ç®—1000ä¸‡
è®¡ç®—ï¼š800/1000Ã—100%=80%ï¼Œå¾—80åˆ†""",
        "opinion_requirements": """- å¿…é¡»åˆ—å‡ºå…·ä½“çš„è®¡ç®—æ•°æ®å’Œæ¥æº
- å±•ç¤ºå®Œæ•´çš„è®¡ç®—å…¬å¼å’Œè®¡ç®—è¿‡ç¨‹
- å¦‚æœ‰å¤šå¹´æ•°æ®ï¼Œéœ€è®¡ç®—åŠ æƒå¹³å‡å€¼
- ç™¾åˆ†æ¯”ä¿ç•™ä¸¤ä½å°æ•°
- ä¸å¾—åŒ…å«ä»»ä½•æœ€ç»ˆå¾—åˆ†æˆ–ç»“è®ºæ€§è¯­å¥"""
    },
    
    "æ¡ä»¶åˆ¤æ–­å¾—åˆ†": {
        "description": "æ ¹æ®æ˜¯å¦æ»¡è¶³ç‰¹å®šæ¡ä»¶æ¥è®¡åˆ†",
        "scoring_guidance": """æ¡ä»¶åˆ¤æ–­å¾—åˆ†æ­¥éª¤ï¼š
1. è¯†åˆ«äº‹å®æ»¡è¶³çš„æ¡ä»¶æ¡£æ¬¡
2. ç»™äºˆè¯¥æ¡£æ¬¡å¯¹åº”çš„åˆ†æ•°

ç¤ºä¾‹ï¼šæ¡ä»¶"é¡¹ç›®æœ‰å®Œæ•´é¢„ç®—"ï¼Œäº‹å®"é¡¹ç›®ç¼–åˆ¶äº†è¯¦ç»†é¢„ç®—"
åˆ¤æ–­ï¼šæ»¡è¶³æ¡ä»¶ï¼Œå¾—100åˆ†""",
        "opinion_requirements": """- æ˜ç¡®è¯´æ˜æ¯ä¸ªæ¡ä»¶çš„æ»¡è¶³/ä¸æ»¡è¶³æƒ…å†µ
- æä¾›å…·ä½“çš„è¯æ®ææ–™æˆ–äº‹å®ä¾æ®
- å¯¹äºä¸æ»¡è¶³çš„æ¡ä»¶ï¼Œè¯´æ˜å…·ä½“ç¼ºå¤±ä»€ä¹ˆ
- ä¸å¾—åŒ…å«ä»»ä½•æœ€ç»ˆå¾—åˆ†æˆ–ç»“è®ºæ€§è¯­å¥"""
    },
    
    "å®šæ€§ä¸å®šé‡ç»“åˆ": {
        "description": "ç»“åˆå®šæ€§æè¿°å’Œå®šé‡æ•°æ®è¿›è¡Œè¯„ä»·",
        "scoring_guidance": """å®šæ€§ä¸å®šé‡ç»“åˆæ­¥éª¤ï¼š
1. åˆ†åˆ«è®¡ç®—å®šé‡å’Œå®šæ€§éƒ¨åˆ†åˆ†æ•°
2. æŒ‰æƒé‡åˆå¹¶åˆ†æ•°

ç¤ºä¾‹ï¼šå®šé‡éƒ¨åˆ†ï¼ˆ60%æƒé‡ï¼‰ï¼šå®Œæˆç‡90%ï¼Œå¾—90åˆ†
å®šæ€§éƒ¨åˆ†ï¼ˆ40%æƒé‡ï¼‰ï¼šè´¨é‡ä¼˜ç§€ï¼Œå¾—95åˆ†
ç»¼åˆå¾—åˆ†ï¼š90Ã—0.6+95Ã—0.4=92åˆ†""",
        "opinion_requirements": """- å®šé‡éƒ¨åˆ†ï¼šåˆ—å‡ºå…·ä½“æ•°æ®ã€ç™¾åˆ†æ¯”ã€é‡‘é¢ç­‰
- å®šæ€§éƒ¨åˆ†ï¼šæè¿°å®åœ°è°ƒç ”ã€è®¿è°ˆç­‰å‘ç°çš„æƒ…å†µ
- ä¸¤éƒ¨åˆ†è¦æœ‰æœºç»“åˆï¼Œä¸èƒ½å‰²è£‚
- å¯¹äºéƒ¨åˆ†è¾¾æ ‡çš„æƒ…å†µï¼Œæ˜ç¡®æ‰£åˆ†æ¯”ä¾‹
- ä¸å¾—åŒ…å«ä»»ä½•æœ€ç»ˆå¾—åˆ†æˆ–ç»“è®ºæ€§è¯­å¥"""
    },
    
    "é€’å‡æ‰£åˆ†æœºåˆ¶": {
        "description": "ä»æ»¡åˆ†å¼€å§‹æ ¹æ®é—®é¢˜æƒ…å†µè¿›è¡Œæ‰£åˆ†",
        "scoring_guidance": """é€’å‡æ‰£åˆ†æœºåˆ¶æ­¥éª¤ï¼š
1. ä»æ»¡åˆ†å¼€å§‹
2. æ ¹æ®é—®é¢˜æ•°é‡æ‰£åˆ†
3. è®¡ç®—æœ€ç»ˆå‰©ä½™åˆ†æ•°

ç¤ºä¾‹ï¼šæ»¡åˆ†100åˆ†ï¼Œæ¯ä¸ªé—®é¢˜æ‰£10åˆ†
å‘ç°3ä¸ªé—®é¢˜ï¼Œæ‰£30åˆ†
æœ€ç»ˆå¾—åˆ†ï¼š100-30=70åˆ†""",
        "opinion_requirements": """- åˆ—å‡ºå‘ç°çš„æ¯ä¸ªé—®é¢˜åŠå…·ä½“è¡¨ç°
- è¯´æ˜æ¯ç±»é—®é¢˜çš„æ‰£åˆ†æ ‡å‡†
- é—®é¢˜è¦å…·ä½“åˆ°æ—¶é—´ã€åœ°ç‚¹ã€è´£ä»»ä¸»ä½“
- ä¸å¾—åŒ…å«ä»»ä½•æœ€ç»ˆå¾—åˆ†æˆ–ç»“è®ºæ€§è¯­å¥"""
    },
    
    "æå…‹ç‰¹é‡è¡¨æ³•": {
        "description": "é€šè¿‡è°ƒæŸ¥é—®å·å’Œç»Ÿè®¡åˆ†æè®¡ç®—æ»¡æ„åº¦",
        "scoring_guidance": """æå…‹ç‰¹é‡è¡¨æ³•æ­¥éª¤ï¼š
1. æ ¹æ®æ»¡æ„åº¦ç™¾åˆ†æ¯”å¯¹åº”åˆ†æ•°æ¡£æ¬¡
2. æˆ–ç›´æ¥å°†æ»¡æ„åº¦ç™¾åˆ†æ¯”ä½œä¸ºå¾—åˆ†

ç¤ºä¾‹ï¼šæ»¡æ„åº¦è°ƒæŸ¥ç»“æœ92.8%
90%ä»¥ä¸Šä¸ºä¼˜ç§€ï¼Œå¾—æ»¡åˆ†
æœ€ç»ˆå¾—åˆ†ï¼š100åˆ†""",
        "opinion_requirements": """- è¯´æ˜è°ƒæŸ¥æ–¹æ³•å’Œæ ·æœ¬é‡
- åˆ—å‡ºå„æ»¡æ„åº¦ç­‰çº§çš„å…·ä½“äººæ•°
- å±•ç¤ºæ»¡æ„åº¦è®¡ç®—å…¬å¼å’Œè¿‡ç¨‹
- æ»¡æ„åº¦ç™¾åˆ†æ¯”ä¿ç•™ä¸¤ä½å°æ•°
- ä¸å¾—åŒ…å«ä»»ä½•æœ€ç»ˆå¾—åˆ†æˆ–ç»“è®ºæ€§è¯­å¥"""
    }
}


class Section(BaseModel):
    """æŠ¥å‘Šç« èŠ‚çš„ç»“æ„åŒ–æ¨¡å‹"""
    section_title: str = Field(..., description="ç« èŠ‚æ ‡é¢˜")
    metric_ids: List[str] = Field(default_factory=list, description="æœ¬ç« èŠ‚å…³è”çš„æŒ‡æ ‡IDåˆ—è¡¨")
    description_prompt: str = Field(..., description="æŒ‡å¯¼æœ¬ç« èŠ‚å†™ä½œçš„æ ¸å¿ƒè¦ç‚¹æˆ–é—®é¢˜")


class ReportStructure(BaseModel):
    """æŠ¥å‘Šæ•´ä½“æ¶æ„çš„ç»“æ„åŒ–æ¨¡å‹"""
    title: str = Field(..., description="æŠ¥å‘Šä¸»æ ‡é¢˜")
    sections: List[Section] = Field(..., description="æŠ¥å‘Šçš„ç« èŠ‚åˆ—è¡¨")


class MetricAnalysisTable(BaseModel):
    """æŒ‡æ ‡åˆ†æè¡¨çš„ç»“æ„åŒ–æ¨¡å‹"""
    data_json: str = Field(..., description="å­˜å‚¨æŒ‡æ ‡åˆ†æç»“æœçš„DataFrame (JSONæ ¼å¼)")


class ArchitectOutput(BaseModel):
    """Architectè¾“å‡ºçš„å¤åˆæ•°æ®ç»“æ„"""
    report_structure: ReportStructure = Field(..., description="æŠ¥å‘Šç»“æ„è®¾è®¡")
    metric_analysis_table: MetricAnalysisTable = Field(..., description="æŒ‡æ ‡åˆ†æè¡¨")


class DesignReportStructure(Action):
    """
    è®¾è®¡æŠ¥å‘Šç»“æ„Action - Architectçš„æ ¸å¿ƒèƒ½åŠ›
    å®ç°ä¸‰ç¯èŠ‚é€»è¾‘ï¼šåˆ†æç®€æŠ¥ -> RAGæ£€ç´¢ -> ç»¼åˆè®¾è®¡
    """
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._research_data: Optional[ResearchData] = None
    
    async def run(self, enhanced_research_context: str, research_data: Optional[ResearchData] = None) -> Tuple[ReportStructure, MetricAnalysisTable]:
        """
        åŸºäºæ ‡å‡†ç»©æ•ˆè¯„ä»·æ¨¡æ¿è®¾è®¡æŠ¥å‘Šç»“æ„ï¼Œå†…å®¹æ ¹æ®é¡¹ç›®ç‰¹ç‚¹å®šåˆ¶
        
        Args:
            enhanced_research_context: å¯èƒ½å·²ç»ç»è¿‡RAGå¢å¼ºçš„ç ”ç©¶ä¸Šä¸‹æ–‡
            research_data: ProductManageræä¾›çš„ç ”ç©¶æ•°æ®ï¼ˆåŒ…å«å‘é‡çŸ¥è¯†åº“ï¼‰
        """
        logger.info("ğŸ—ï¸ å¼€å§‹åŸºäºæ ‡å‡†æ¨¡æ¿çš„æŠ¥å‘Šç»“æ„è®¾è®¡...")
        self._research_data = research_data
        
        # ä»å¢å¼ºä¸Šä¸‹æ–‡ä¸­æå–åŸå§‹ç ”ç©¶ç®€æŠ¥
        research_brief = self._extract_original_brief(enhanced_research_context)
        
        # æ­¥éª¤ä¸€ï¼šé¡¹ç›®ä¿¡æ¯æå– - ä»ç ”ç©¶ç®€æŠ¥å’ŒRAGä¸­æå–é¡¹ç›®æ ¸å¿ƒä¿¡æ¯
        logger.info("ğŸ“‹ æ­¥éª¤ä¸€ï¼šæå–é¡¹ç›®æ ¸å¿ƒä¿¡æ¯...")
        project_info = await self._extract_project_info(research_brief)
        
        # æ­¥éª¤äºŒï¼šRAGå¢å¼º - æŸ¥è¯¢è¯¦ç»†èµ„æ–™ä¸°å¯Œé¡¹ç›®ä¿¡æ¯
        logger.info("ğŸ” æ­¥éª¤äºŒï¼šRAGæ£€ç´¢å¢å¼ºé¡¹ç›®ä¿¡æ¯...")
        enriched_info = await self._enrich_with_rag(project_info)
        
        # æ­¥éª¤ä¸‰ï¼šæ ‡å‡†ç»“æ„å®šåˆ¶ - åŸºäºå›ºå®šæ¨¡æ¿ç”Ÿæˆå®šåˆ¶åŒ–å†…å®¹
        logger.info("ğŸ—ï¸ æ­¥éª¤ä¸‰ï¼šåŸºäºæ ‡å‡†æ¨¡æ¿ç”Ÿæˆå®šåˆ¶åŒ–å†…å®¹...")
        report_structure, metric_table = await self._generate_customized_template(enriched_info)
        
        logger.info(f"âœ… æŠ¥å‘Šè“å›¾è®¾è®¡å®Œæˆ: {report_structure.title}")
        logger.info(f"ğŸ“Š æŒ‡æ ‡ä½“ç³»: {len(json.loads(metric_table.data_json))} ä¸ªæŒ‡æ ‡")
        
        return report_structure, metric_table
    
    def _extract_original_brief(self, enhanced_context: str) -> str:
        """ä»å¢å¼ºä¸Šä¸‹æ–‡ä¸­æå–åŸå§‹ç ”ç©¶ç®€æŠ¥"""
        # å¦‚æœåŒ…å«RAGå¢å¼ºå†…å®¹ï¼Œæå–åŸå§‹éƒ¨åˆ†
        if "### RAGæ£€ç´¢å¢å¼ºå†…å®¹" in enhanced_context:
            parts = enhanced_context.split("### RAGæ£€ç´¢å¢å¼ºå†…å®¹")
            return parts[0].strip()
        return enhanced_context
    
    async def _extract_project_info(self, research_brief: str) -> dict:
        """
        æ­¥éª¤ä¸€ï¼šä»ç ”ç©¶ç®€æŠ¥ä¸­æå–é¡¹ç›®æ ¸å¿ƒä¿¡æ¯
        """
        extraction_prompt = PROJECT_INFO_EXTRACTION_PROMPT.format(research_brief=research_brief)
        
        try:
            extraction_result = await self._aask(extraction_prompt, [ARCHITECT_BASE_SYSTEM])
            
            # ä»LLMå›å¤ä¸­æå–JSONå†…å®¹
            project_info = self._extract_json_from_llm_response(extraction_result)
            
            logger.info(f"ğŸ“‹ é¡¹ç›®åç§°: {project_info.get('project_name', 'æœªçŸ¥é¡¹ç›®')}")
            logger.info(f"ğŸ“‹ é¡¹ç›®ç±»å‹: {project_info.get('project_type', 'å¾…è¡¥å……')}")
            return project_info
        except Exception as e:
            logger.error(f"é¡¹ç›®ä¿¡æ¯æå–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­è®¾è®¡: {e}")
            raise ValueError(f"æ— æ³•ä»ç ”ç©¶ç®€æŠ¥ä¸­æå–æœ‰æ•ˆé¡¹ç›®ä¿¡æ¯: {e}")
    
    def _extract_json_from_llm_response(self, response: str) -> dict:
        """
        ä»LLMå›å¤ä¸­æå–JSONå†…å®¹ï¼Œå¤„ç†markdownæ ¼å¼å’Œé¢å¤–è¯´æ˜
        """
        try:
            # æ–¹æ³•1ï¼šå°è¯•ç›´æ¥è§£æï¼ˆå¦‚æœæ˜¯çº¯JSONï¼‰
            return json.loads(response)
        except:
            pass
        
        try:
            # æ–¹æ³•2ï¼šæå–```jsonä»£ç å—ä¸­çš„å†…å®¹
            import re
            json_pattern = r'```json\s*(.*?)\s*```'
            match = re.search(json_pattern, response, re.DOTALL)
            if match:
                json_str = match.group(1).strip()
                return json.loads(json_str)
        except:
            pass
        
        try:
            # æ–¹æ³•3ï¼šæŸ¥æ‰¾å¤§æ‹¬å·åŒ…å›´çš„JSONå†…å®¹
            start_idx = response.find('{')
            if start_idx != -1:
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ª{ï¼Œç„¶åæ‰¾åˆ°åŒ¹é…çš„}
                brace_count = 0
                end_idx = start_idx
                for i, char in enumerate(response[start_idx:], start_idx):
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            end_idx = i
                            break
                
                if brace_count == 0:
                    json_str = response[start_idx:end_idx+1]
                    return json.loads(json_str)
        except:
            pass
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
        raise ValueError(f"æ— æ³•ä»LLMå›å¤ä¸­æå–æœ‰æ•ˆJSON: {response[:200]}...")
    
    async def _enrich_with_rag(self, project_info: dict) -> dict:
        """
        æ­¥éª¤äºŒï¼šé€šè¿‡RAGæ£€ç´¢ä¸°å¯Œé¡¹ç›®ä¿¡æ¯ - åŠ¨æ€ç”Ÿæˆæ£€ç´¢å…³é”®è¯
        """
        if not self._research_data or not self._research_data.content_chunks:
            logger.error("âŒ å‘é‡çŸ¥è¯†åº“ä¸å¯ç”¨ï¼æ— æ³•è¿›è¡ŒRAGå¢å¼º")
            raise ValueError("å‘é‡çŸ¥è¯†åº“ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒRAGå¢å¼ºã€‚è¯·ç¡®ä¿ResearchDataåŒ…å«æœ‰æ•ˆçš„content_chunks")
        
        # åŠ¨æ€ç”Ÿæˆæ£€ç´¢å…³é”®è¯
        search_keywords = await self._generate_rag_search_keywords(project_info)
        
        enriched_info = project_info.copy()
        enriched_info["rag_evidence"] = {}
        
        logger.info(f"ğŸ” å¼€å§‹å¯¹ {len(search_keywords)} ä¸ªåŠ¨æ€å…³é”®è¯è¿›è¡ŒRAGæ£€ç´¢...")
        
        # é€ä¸ªç±»åˆ«æ£€ç´¢
        for keyword_group in search_keywords:
            category = keyword_group["category"]
            keywords = keyword_group["keywords"]
            
            category_evidence = []
            for keyword in keywords:
                try:
                    relevant_chunks = await self._search_chunks(keyword)
                    if relevant_chunks:
                        category_evidence.extend(relevant_chunks[:2])
                except Exception as e:
                    logger.warning(f"å…³é”®è¯ '{keyword}' æ£€ç´¢å¤±è´¥: {e}")
            
            if category_evidence:
                enriched_info["rag_evidence"][category] = category_evidence
                logger.debug(f"ğŸ“‹ {category}: æ£€ç´¢åˆ° {len(category_evidence)} æ¡ç›¸å…³è¯æ®")
        
        # æœ€åæ¸…ç†é‡å¤å†…å®¹å¹¶é™åˆ¶æ•°é‡
        for category in enriched_info["rag_evidence"]:
            # å»é‡å¹¶é™åˆ¶æ•°é‡
            unique_chunks = list(dict.fromkeys(enriched_info["rag_evidence"][category]))
            enriched_info["rag_evidence"][category] = unique_chunks[:6]  # æ¯ä¸ªç±»åˆ«æœ€å¤š6æ¡
            logger.debug(f"ğŸ“‹ {category}: æœ€ç»ˆæ£€ç´¢åˆ° {len(enriched_info['rag_evidence'][category])} æ¡ç›¸å…³è¯æ®")
        
        logger.info(f"ğŸ“‹ RAGæ£€ç´¢å®Œæˆï¼Œä¸°å¯Œäº† {len(enriched_info['rag_evidence'])} ä¸ªä¿¡æ¯ç±»åˆ«")
        return enriched_info
    
    async def _generate_rag_search_keywords(self, project_info: dict) -> List[dict]:
        """
        åŠ¨æ€ç”ŸæˆRAGæ£€ç´¢å…³é”®è¯ï¼ˆç±»ä¼¼PMçš„å…³é”®è¯ç”Ÿæˆé€»è¾‘ï¼‰
        """
        project_name = project_info.get('project_name', 'é¡¹ç›®')
        
        keyword_generation_prompt = RAG_KEYWORDS_GENERATION_PROMPT.format(
            project_info=json.dumps(project_info, ensure_ascii=False, indent=2),
            project_name=project_name
        )
        
        try:
            keywords_result = await self._aask(keyword_generation_prompt)
            
            # ä½¿ç”¨åŒæ ·çš„JSONæå–é€»è¾‘
            search_keywords = self._extract_json_from_llm_response(keywords_result)
            
            logger.info(f"ğŸ” åŠ¨æ€ç”Ÿæˆäº† {len(search_keywords)} ä¸ªå…³é”®è¯ç»„")
            return search_keywords
        except Exception as e:
            logger.warning(f"åŠ¨æ€å…³é”®è¯ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å…³é”®è¯: {e}")
            # åŸºç¡€å…³é”®è¯ä½œä¸ºå¤‡ç”¨
            return [
                {"category": "é¡¹ç›®åŸºæœ¬ä¿¡æ¯", "keywords": ["é¡¹ç›®åç§°", "é¡¹ç›®èƒŒæ™¯", "ä¸»è¦ç›®æ ‡"]},
                {"category": "èµ„é‡‘é¢„ç®—", "keywords": ["é¢„ç®—é‡‘é¢", "èµ„é‡‘æ¥æº", "æ”¯å‡ºæ˜ç»†"]},
                {"category": "å®æ–½å†…å®¹", "keywords": ["å®æ–½æ–¹æ¡ˆ", "æŠ€æœ¯æªæ–½", "ç®¡ç†æµç¨‹"]},
                {"category": "ç»©æ•ˆæŒ‡æ ‡", "keywords": ["è¯„ä»·æŒ‡æ ‡", "æˆæœäº§å‡º", "æ•ˆç›Šåˆ†æ"]}
            ]
    
    async def _search_chunks(self, query: str) -> List[str]:
        """
        ğŸ§  ä½¿ç”¨æ™ºèƒ½æ£€ç´¢æœåŠ¡è¿›è¡Œå¢å¼ºæ£€ç´¢
        """
        try:
            from backend.services.intelligent_search import intelligent_search
            
            # ğŸ§  ä½¿ç”¨æ™ºèƒ½æ£€ç´¢æœåŠ¡
            if self._research_data and hasattr(self._research_data, 'vector_store_path'):
                search_result = await intelligent_search.intelligent_search(
                    query=query,
                    project_vector_storage_path=self._research_data.vector_store_path,
                    mode="hybrid",  # ä½¿ç”¨æ··åˆæ™ºèƒ½æ£€ç´¢ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹æ³•
                    enable_global=True,
                    max_results=5
                )
                
                results = search_result.get("results", [])
                
                # ğŸ§  æ·»åŠ æ™ºèƒ½åˆ†ææ´å¯Ÿåˆ°ç»“æœä¸­
                if search_result.get("insights"):
                    insights_text = "\nğŸ’¡ æ™ºèƒ½åˆ†ææ´å¯Ÿ:\n" + "\n".join(search_result["insights"])
                    if results:
                        results[0] = results[0] + insights_text
                    else:
                        results = [insights_text]
                
                logger.debug(f"ğŸ§  æ™ºèƒ½æ£€ç´¢å®Œæˆï¼ŒæŸ¥è¯¢: '{query}'ï¼Œæ¨¡å¼: {search_result.get('mode_used', 'unknown')}ï¼Œæ‰¾åˆ° {len(results)} æ¡ç›¸å…³å†…å®¹")
                return results
                    
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    async def _generate_customized_template(self, enriched_info: dict) -> Tuple[ReportStructure, MetricAnalysisTable]:
        """
        æ­¥éª¤ä¸‰ï¼šåŸºäºæ ‡å‡†ç»©æ•ˆè¯„ä»·æ¨¡æ¿ç”Ÿæˆå®šåˆ¶åŒ–å†…å®¹
        """
        # æ ‡å‡†ç»©æ•ˆè¯„ä»·æŠ¥å‘Šç»“æ„ï¼ˆåŸºäºreportmodel.yamlï¼‰
        standard_sections = [
            {
                "title": "ä¸€ã€é¡¹ç›®æ¦‚è¿°",
                "key": "overview",
                "prompt_template": "è¯·å›´ç»•ä»¥ä¸‹æ–¹é¢è¯¦ç»†æè¿°é¡¹ç›®æ¦‚å†µï¼š1. é¡¹ç›®ç«‹é¡¹èƒŒæ™¯åŠç›®çš„ã€é¡¹ç›®ä¸»è¦å†…å®¹ï¼›2. èµ„é‡‘æŠ•å…¥å’Œä½¿ç”¨æƒ…å†µã€é¡¹ç›®å®æ–½æƒ…å†µï¼›3. é¡¹ç›®ç»„ç»‡ç®¡ç†ï¼›4. é¡¹ç›®ç»©æ•ˆç›®æ ‡ï¼šé€šè¿‡çŸ¥è¯†åº“æœç´¢ç»©æ•ˆç›®æ ‡è¡¨å¤åˆ¶ç›¸å…³å†…å®¹ï¼ŒåŠ¡å¿…ä»¥è¡¨æ ¼å½¢å¼å±•ç¤ºé¡¹ç›®ç»©æ•ˆæŒ‡æ ‡"
            },
            {
                "title": "äºŒã€ç»¼åˆç»©æ•ˆè¯„ä»·ç»“è®º",
                "key": "conclusion", 
                "prompt_template": "è¯·åŸºäºå¯¹é¡¹ç›®å†³ç­–ã€è¿‡ç¨‹ã€äº§å‡ºå’Œæ•ˆç›Šå››ä¸ªç»´åº¦çš„å…¨é¢ç»©æ•ˆåˆ†æï¼Œç»™å‡ºé¡¹ç›®çš„ç»¼åˆè¯„ä»·ç»“è®ºã€‚åº”åŒ…å«é¡¹ç›®æ€»å¾—åˆ†ã€è¯„ä»·ç­‰çº§ï¼Œå¹¶åŠ¡å¿…ä»¥è¡¨æ ¼å½¢å¼æ¸…æ™°å±•ç¤ºå„ä¸€çº§æŒ‡æ ‡ï¼ˆå†³ç­–ã€è¿‡ç¨‹ã€äº§å‡ºã€æ•ˆç›Šï¼‰çš„è®¡åˆ’åˆ†å€¼ã€å®é™…å¾—åˆ†å’Œå¾—åˆ†ç‡"
            },
            {
                "title": "ä¸‰ã€ä¸»è¦æˆæ•ˆåŠç»éªŒ",
                "key": "achievements",
                "prompt_template": "è¯·è¯¦ç»†æ€»ç»“é¡¹ç›®å®æ–½è¿‡ç¨‹ä¸­æ‰€å–å¾—çš„å„é¡¹ä¸»è¦æˆæ•ˆï¼Œéœ€ç»“åˆå…·ä½“æ•°æ®å’Œäº‹å®è¿›è¡Œé˜è¿°ã€‚åŒæ—¶ï¼Œæç‚¼å‡ºé¡¹ç›®åœ¨æ”¿ç­–æ‰§è¡Œã€èµ„é‡‘ç®¡ç†ã€éƒ¨é—¨ååŒã€æœåŠ¡ä¼˜åŒ–ç­‰æ–¹é¢å¯ä¾›å…¶ä»–åœ°åŒºæˆ–ç±»ä¼¼é¡¹ç›®å€Ÿé‰´çš„æˆåŠŸç»éªŒå’Œæœ‰æ•ˆåšæ³•"
            },
            {
                "title": "å››ã€å­˜åœ¨çš„é—®é¢˜å’ŒåŸå› åˆ†æ",
                "key": "problems",
                "prompt_template": "è¯·æ ¹æ®è°ƒç ”ï¼ˆå¦‚é—®å·è°ƒæŸ¥ã€è®¿è°ˆï¼‰å’Œæ•°æ®åˆ†æï¼Œå®¢è§‚ã€å‡†ç¡®åœ°æŒ‡å‡ºé¡¹ç›®åœ¨å®æ–½è¿‡ç¨‹ä¸­å­˜åœ¨çš„ä¸»è¦é—®é¢˜ã€‚å¯¹äºæ¯ä¸ªè¯†åˆ«å‡ºçš„é—®é¢˜ï¼Œéƒ½åº”æ·±å…¥å‰–æå…¶äº§ç”Ÿçš„å†…å¤–éƒ¨åŸå› "
            },
            {
                "title": "äº”ã€æ”¹è¿›å»ºè®®",
                "key": "suggestions",
                "prompt_template": "é’ˆå¯¹åœ¨'å­˜åœ¨çš„é—®é¢˜å’ŒåŸå› åˆ†æ'éƒ¨åˆ†æŒ‡å‡ºçš„å„é¡¹ä¸»è¦é—®é¢˜ï¼Œè¯·é€æ¡æå‡ºå…·ä½“çš„ã€æœ‰é’ˆå¯¹æ€§çš„ã€å¯æ“ä½œçš„æ”¹è¿›å»ºè®®ã€‚å»ºè®®åº”æ˜ç¡®æ”¹è¿›æ–¹å‘ã€è´£ä»»ä¸»ä½“å’Œé¢„æœŸæ•ˆæœ"
            }
        ]
        
        # åŸºäºé¡¹ç›®ä¿¡æ¯å®šåˆ¶å†…å®¹æè¿°
        customized_sections = await self._customize_section_content(standard_sections, enriched_info)
        
        # ç”Ÿæˆæ ‡å‡†æŒ‡æ ‡ä½“ç³»
        metric_table = await self._generate_standard_metrics(enriched_info)
        
        # æ„é€ ReportStructure
        sections = []
        for section_data in customized_sections:
            section = Section(
                section_title=section_data["title"],
                metric_ids=section_data.get("metric_ids", []),
                description_prompt=section_data["description_prompt"]
            )
            sections.append(section)
        
        project_name = enriched_info.get('project_name', 'é¡¹ç›®')
        report_structure = ReportStructure(
            title=f"{project_name}ç»©æ•ˆè¯„ä»·æŠ¥å‘Š",
            sections=sections
        )
        
        return report_structure, metric_table
    
    async def _customize_section_content(self, standard_sections: List[dict], enriched_info: dict) -> List[dict]:
        """
        å®šåˆ¶åŒ–ç« èŠ‚å†…å®¹æè¿°
        """
        customized_sections = []
        project_name = enriched_info.get('project_name', 'é¡¹ç›®')
        
        for section in standard_sections:
            # åŸºäºé¡¹ç›®ä¿¡æ¯è°ƒæ•´prompt
            customized_prompt = await self._generate_section_prompt(section, enriched_info)
            
            customized_section = {
                "title": section["title"],
                "description_prompt": customized_prompt,
                "metric_ids": []
            }
            
            # ä¸º"é¡¹ç›®æ¦‚è¿°"ç« èŠ‚æ·»åŠ æŒ‡æ ‡å…³è”
            if "æ¦‚è¿°" in section["title"]:
                customized_section["metric_ids"] = ["project_scope", "budget_execution", "target_completion"]
            elif "è¯„ä»·ç»“è®º" in section["title"]:
                customized_section["metric_ids"] = ["overall_score", "decision_score", "process_score", "output_score", "benefit_score"]
                
            customized_sections.append(customized_section)
        
        return customized_sections
    
    async def _generate_section_prompt(self, section: dict, enriched_info: dict) -> str:
        """
        ç”Ÿæˆç‰¹å®šç« èŠ‚çš„å†™ä½œæŒ‡å¯¼prompt - åŸºäºRAGè¯æ®ç»™å‡ºå…·ä½“æ£€ç´¢æŒ‡å¯¼
        """
        base_prompt = section["prompt_template"]
        project_name = enriched_info.get('project_name', 'é¡¹ç›®')
        section_title = section["title"]
        
        # æ ¹æ®ç« èŠ‚ç‰¹ç‚¹ç”Ÿæˆå…·ä½“çš„RAGæ£€ç´¢æŒ‡å¯¼
        rag_instructions = await self._generate_chapter_rag_instructions(section_title, enriched_info)
        
        customized_prompt = SECTION_PROMPT_GENERATION_TEMPLATE.format(
            project_name=project_name,
            base_prompt=base_prompt,
            rag_instructions=rag_instructions
        )
        
        return customized_prompt
    
    async def _generate_chapter_rag_instructions(self, section_title: str, enriched_info: dict) -> str:
        """
        ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå…·ä½“çš„RAGæ£€ç´¢æŒ‡å¯¼
        """
        rag_evidence = enriched_info.get("rag_evidence", {})
        
        # æ ¹æ®ç« èŠ‚æ ‡é¢˜ç”Ÿæˆå…·ä½“çš„æ£€ç´¢æŒ‡å¯¼
        if "é¡¹ç›®æ¦‚è¿°" in section_title:
            instructions = f"""
**1. é¡¹ç›®ç«‹é¡¹èƒŒæ™¯åŠç›®çš„**
   - æ£€ç´¢å…³é”®è¯ï¼š{self._get_evidence_summary(rag_evidence, "é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡")}
   - é‡ç‚¹æŸ¥æ‰¾ï¼šæ”¿ç­–æ–‡ä»¶å¼•ç”¨ã€ç«‹é¡¹ä¾æ®ã€ç›®æ ‡è®¾å®š
   
**2. èµ„é‡‘æŠ•å…¥å’Œä½¿ç”¨æƒ…å†µ**
   - æ£€ç´¢å…³é”®è¯ï¼š{self._get_evidence_summary(rag_evidence, "èµ„é‡‘ä¸é¢„ç®—")}
   - é‡ç‚¹æŸ¥æ‰¾ï¼šé¢„ç®—æ€»é¢ã€èµ„é‡‘æ¥æºã€åˆ†é…æ˜ç»†ã€æ‰§è¡Œè¿›åº¦
   
**3. é¡¹ç›®ç»„ç»‡ç®¡ç†**
   - æ£€ç´¢å…³é”®è¯ï¼š{self._get_evidence_summary(rag_evidence, "å®æ–½æ–¹æ¡ˆ")}
   - é‡ç‚¹æŸ¥æ‰¾ï¼šç®¡ç†æœºæ„ã€èŒè´£åˆ†å·¥ã€æµç¨‹åˆ¶åº¦
   
**4. é¡¹ç›®ç»©æ•ˆç›®æ ‡**
   - æ£€ç´¢å…³é”®è¯ï¼š{self._get_evidence_summary(rag_evidence, "æ•ˆæœä¸æˆæ•ˆ")}
   - é‡ç‚¹æŸ¥æ‰¾ï¼šç»©æ•ˆç›®æ ‡è¡¨ã€æŒ‡æ ‡è®¾å®šã€é¢„æœŸæˆæœï¼ˆåŠ¡å¿…ä»¥è¡¨æ ¼å½¢å¼å±•ç¤ºï¼‰
"""
        elif "ç»¼åˆç»©æ•ˆè¯„ä»·ç»“è®º" in section_title:
            instructions = f"""
**å†³ç­–ã€è¿‡ç¨‹ã€äº§å‡ºã€æ•ˆç›Šå››ä¸ªç»´åº¦åˆ†æ**
   - æ£€ç´¢å…³é”®è¯ï¼š{self._get_evidence_summary(rag_evidence, "æ•ˆæœä¸æˆæ•ˆ")}
   - é‡ç‚¹æŸ¥æ‰¾ï¼šå„é¡¹æŒ‡æ ‡å®Œæˆæƒ…å†µã€è¯„åˆ†ç»“æœã€ç»¼åˆå¾—åˆ†
   - å¿…é¡»è¾“å‡ºï¼šæŒ‡æ ‡å¾—åˆ†æƒ…å†µè¡¨ï¼ˆä¸€çº§æŒ‡æ ‡ã€åˆ†å€¼ã€å¾—åˆ†ã€å¾—åˆ†ç‡ï¼‰
"""
        elif "ä¸»è¦æˆæ•ˆåŠç»éªŒ" in section_title:
            instructions = f"""
**å…·ä½“æˆæ•ˆæ•°æ®**
   - æ£€ç´¢å…³é”®è¯ï¼š{self._get_evidence_summary(rag_evidence, "æ•ˆæœä¸æˆæ•ˆ")}
   - é‡ç‚¹æŸ¥æ‰¾ï¼šé‡åŒ–æˆæœæ•°æ®ã€å—ç›Šäººç¾¤ç»Ÿè®¡ã€æ•ˆæœå¯¹æ¯”
   
**æˆåŠŸç»éªŒæ€»ç»“**
   - æ£€ç´¢å…³é”®è¯ï¼š{self._get_evidence_summary(rag_evidence, "å®æ–½æ–¹æ¡ˆ")}
   - é‡ç‚¹æŸ¥æ‰¾ï¼šåˆ›æ–°åšæ³•ã€ç®¡ç†ç»éªŒã€æŠ€æœ¯äº®ç‚¹
"""
        elif "å­˜åœ¨çš„é—®é¢˜å’ŒåŸå› åˆ†æ" in section_title:
            instructions = f"""
**é—®é¢˜è¯†åˆ«**
   - æ£€ç´¢å…³é”®è¯ï¼š{self._get_evidence_summary(rag_evidence, "é£é™©ä¸æŒ‘æˆ˜")}
   - é‡ç‚¹æŸ¥æ‰¾ï¼šè°ƒç ”å‘ç°çš„é—®é¢˜ã€æ•°æ®åæ˜ çš„ä¸è¶³ã€åé¦ˆæ„è§
   
**åŸå› æ·±åº¦åˆ†æ**
   - æ£€ç´¢å…³é”®è¯ï¼šæ”¿ç­–æ‰§è¡Œã€ç®¡ç†åˆ¶åº¦ã€æŠ€æœ¯æ¡ä»¶ã€å¤–éƒ¨ç¯å¢ƒ
   - é‡ç‚¹æŸ¥æ‰¾ï¼šé—®é¢˜äº§ç”Ÿçš„å†…åœ¨æœºåˆ¶å’Œå¤–éƒ¨å› ç´ 
"""
        elif "æ”¹è¿›å»ºè®®" in section_title:
            instructions = f"""
**é’ˆå¯¹æ€§å»ºè®®**
   - åŸºäºå‰è¿°é—®é¢˜åˆ†æï¼Œæ£€ç´¢å…³é”®è¯ï¼š{self._get_evidence_summary(rag_evidence, "é£é™©ä¸æŒ‘æˆ˜")}
   - é‡ç‚¹æŸ¥æ‰¾ï¼šæ”¹è¿›æªæ–½ã€æ”¿ç­–å»ºè®®ã€æŠ€æœ¯ä¼˜åŒ–æ–¹æ¡ˆ
   
**å¯æ“ä½œæ€§éªŒè¯**
   - æ£€ç´¢å…³é”®è¯ï¼šæˆåŠŸæ¡ˆä¾‹ã€æœ€ä½³å®è·µã€æ”¿ç­–æ”¯æŒ
   - é‡ç‚¹æŸ¥æ‰¾ï¼šç±»ä¼¼é¡¹ç›®çš„æ”¹è¿›ç»éªŒã€æ”¿ç­–å¯è¡Œæ€§åˆ†æ
"""
        else:
            # é€šç”¨æŒ‡å¯¼
            instructions = f"""
**é€šç”¨æ£€ç´¢æŒ‡å¯¼**
   - ä¼˜å…ˆæ£€ç´¢ï¼šé¡¹ç›®ç›¸å…³çš„å…·ä½“æ•°æ®ã€æ”¿ç­–æ–‡ä»¶ã€å®æ–½æ•ˆæœ
   - é‡ç‚¹å…³æ³¨ï¼šæ•°é‡åŒ–æŒ‡æ ‡ã€æ—¶é—´èŠ‚ç‚¹ã€è´£ä»»ä¸»ä½“ã€å…·ä½“æªæ–½
"""
        
        return instructions
    
    def _get_evidence_summary(self, rag_evidence: dict, category: str) -> str:
        """
        è·å–ç‰¹å®šç±»åˆ«çš„RAGè¯æ®æ‘˜è¦ï¼Œç”¨äºæŒ‡å¯¼æ£€ç´¢
        """
        if category in rag_evidence and rag_evidence[category]:
            # ä»è¯æ®ä¸­æå–å…³é”®è¯ä½œä¸ºæ£€ç´¢æŒ‡å¯¼
            evidence_text = " ".join(rag_evidence[category][:2])  # å–å‰2æ¡è¯æ®
            # ç®€å•æå–å…³é”®æ¦‚å¿µ
            keywords = []
            if "é¢„ç®—" in evidence_text or "èµ„é‡‘" in evidence_text:
                keywords.append("é¢„ç®—èµ„é‡‘æ•°æ®")
            if "ç›®æ ‡" in evidence_text or "æŒ‡æ ‡" in evidence_text:
                keywords.append("ç›®æ ‡æŒ‡æ ‡è®¾å®š")
            if "å®æ–½" in evidence_text or "ç®¡ç†" in evidence_text:
                keywords.append("å®æ–½ç®¡ç†æªæ–½")
            if "æ•ˆæœ" in evidence_text or "æˆæœ" in evidence_text:
                keywords.append("å®æ–½æ•ˆæœæ•°æ®")
            
            return ", ".join(keywords) if keywords else "ç›¸å…³é¡¹ç›®ä¿¡æ¯"
        return "é¡¹ç›®ç›¸å…³ä¿¡æ¯ï¼ˆå¾…æ£€ç´¢ï¼‰"
    
    async def _generate_standard_metrics(self, enriched_info: dict) -> MetricAnalysisTable:
        """
        åŸºäºé¡¹ç›®ç‰¹ç‚¹åŠ¨æ€ç”Ÿæˆç»©æ•ˆæŒ‡æ ‡ä½“ç³»
        ä¸€çº§æŒ‡æ ‡å›ºå®šä¸ºï¼šå†³ç­–ã€è¿‡ç¨‹ã€äº§å‡ºã€æ•ˆç›Š
        äºŒçº§ã€ä¸‰çº§æŒ‡æ ‡æ ¹æ®é¡¹ç›®ç‰¹ç‚¹ç”±LLMåŠ¨æ€ç”Ÿæˆ
        """
        project_name = enriched_info.get('project_name', 'é¡¹ç›®')
        project_type = enriched_info.get('project_type', 'è´¢æ”¿æ”¯å‡ºé¡¹ç›®')
        
        # æ„é€ æŒ‡æ ‡è®¾è®¡prompt
        metrics_design_prompt = METRICS_DESIGN_PROMPT.format(
            project_info=json.dumps(enriched_info, ensure_ascii=False, indent=2),
            project_name=project_name,
            project_type=project_type
        )
        
        try:
            metrics_result = await self._aask(metrics_design_prompt, [ARCHITECT_BASE_SYSTEM])
            
            # ä»LLMå›å¤ä¸­æå–JSONå†…å®¹
            metrics_data = self._extract_json_from_llm_response(metrics_result)
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§å’Œä¸€çº§æŒ‡æ ‡åˆ†å¸ƒ
            validated_metrics = self._validate_metrics_structure(metrics_data)
            
            logger.info(f"ğŸ“Š åŠ¨æ€ç”Ÿæˆäº† {len(validated_metrics)} ä¸ªç»©æ•ˆæŒ‡æ ‡")
            logger.info(f"ğŸ“Š æŒ‡æ ‡åˆ†å¸ƒ - å†³ç­–:{self._count_metrics_by_level1(validated_metrics, 'å†³ç­–')}ä¸ª, "
                       f"è¿‡ç¨‹:{self._count_metrics_by_level1(validated_metrics, 'è¿‡ç¨‹')}ä¸ª, "
                       f"äº§å‡º:{self._count_metrics_by_level1(validated_metrics, 'äº§å‡º')}ä¸ª, "
                       f"æ•ˆç›Š:{self._count_metrics_by_level1(validated_metrics, 'æ•ˆç›Š')}ä¸ª")
            
            return MetricAnalysisTable(data_json=json.dumps(validated_metrics, ensure_ascii=False))
            
        except Exception as e:
            logger.error(f"LLMæŒ‡æ ‡ç”Ÿæˆå¤±è´¥ï¼Œæ¡ä»¶ä¸è¶³æ— æ³•æ„å»ºæŒ‡æ ‡ä½“ç³»: {e}")
            # ä¸ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼Œç›´æ¥è¿”å›ç©ºæŒ‡æ ‡è¡¨ç¤ºæ— æ³•æ„å»º
            empty_metrics = {
                "error": "æ¡ä»¶ä¸è¶³ï¼Œæ— æ³•æ„å»ºæŒ‡æ ‡ä½“ç³»",
                "reason": str(e),
                "suggestion": "è¯·ç¡®ä¿é¡¹ç›®ä¿¡æ¯å®Œæ•´åé‡æ–°ç”Ÿæˆ"
            }
            return MetricAnalysisTable(data_json=json.dumps(empty_metrics, ensure_ascii=False))
    
    def _validate_metrics_structure(self, metrics_data: List[dict]) -> List[dict]:
        """
        éªŒè¯æŒ‡æ ‡æ•°æ®ç»“æ„çš„å®Œæ•´æ€§
        """
        validated_metrics = []
        # ğŸ”§ ä¿®å¤ï¼šæ”¯æŒå¤šç§å­—æ®µåæ ¼å¼ï¼Œå…¼å®¹æ–°çš„æŒ‡æ ‡ç»“æ„
        required_fields = ['metric_id', 'name', 'category', 'ä¸€çº§æŒ‡æ ‡', 'äºŒçº§æŒ‡æ ‡', 'ä¸‰çº§æŒ‡æ ‡', 'åˆ†å€¼']
        # å¯é€‰å­—æ®µï¼Œæ”¯æŒå¤šç§æ ¼å¼
        optional_fields = [
            ('evaluation_type', 'è¯„ä»·ç±»å‹'),
            ('evaluation_points', 'è¯„ä»·è¦ç‚¹'), 
            ('scoring_method', 'è¯„åˆ†æ–¹æ³•', 'è¯„åˆ†è§„åˆ™'),
            ('è¯„åˆ†è¿‡ç¨‹', 'è¯„åˆ†è¿‡ç¨‹')
        ]
        
        for metric in metrics_data:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if all(field in metric for field in required_fields):
                # ç¡®ä¿ä¸€çº§æŒ‡æ ‡åªèƒ½æ˜¯å›ºå®šçš„å››ä¸ªå€¼
                if metric['ä¸€çº§æŒ‡æ ‡'] in ['å†³ç­–', 'è¿‡ç¨‹', 'äº§å‡º', 'æ•ˆç›Š']:
                    # ğŸ”§ æ ‡å‡†åŒ–å­—æ®µåï¼Œç¡®ä¿å…¼å®¹æ€§
                    standardized_metric = metric.copy()
                    
                    # å¤„ç†è¯„åˆ†æ–¹æ³•å­—æ®µçš„å¤šç§æ ¼å¼
                    if 'scoring_method' not in standardized_metric:
                        if 'è¯„åˆ†æ–¹æ³•' in standardized_metric:
                            standardized_metric['scoring_method'] = standardized_metric['è¯„åˆ†æ–¹æ³•']
                        elif 'è¯„åˆ†è§„åˆ™' in standardized_metric:
                            standardized_metric['scoring_method'] = standardized_metric['è¯„åˆ†è§„åˆ™']
                    
                    # ç¡®ä¿æœ‰è¯„åˆ†è¿‡ç¨‹å­—æ®µ
                    if 'è¯„åˆ†è¿‡ç¨‹' not in standardized_metric:
                        if 'evaluation_process' in standardized_metric:
                            standardized_metric['è¯„åˆ†è¿‡ç¨‹'] = standardized_metric['evaluation_process']
                        else:
                            standardized_metric['è¯„åˆ†è¿‡ç¨‹'] = f"å¯¹æŒ‡æ ‡'{metric.get('name', 'æœªçŸ¥æŒ‡æ ‡')}'è¿›è¡Œä¸“ä¸šè¯„ä»·"
                    
                    validated_metrics.append(standardized_metric)
                    logger.debug(f"âœ… éªŒè¯é€šè¿‡æŒ‡æ ‡: {metric.get('name', 'æœªçŸ¥æŒ‡æ ‡')}")
                else:
                    logger.warning(f"æŒ‡æ ‡ {metric.get('name', 'æœªçŸ¥')} çš„ä¸€çº§æŒ‡æ ‡ä¸ç¬¦åˆè¦æ±‚: {metric.get('ä¸€çº§æŒ‡æ ‡', '')}")
            else:
                missing_fields = [field for field in required_fields if field not in metric]
                logger.warning(f"æŒ‡æ ‡æ•°æ®ä¸å®Œæ•´ï¼Œç¼ºå¤±å­—æ®µ {missing_fields}: {metric.get('name', 'æœªçŸ¥æŒ‡æ ‡')}")
        
        return validated_metrics
    
    def _count_metrics_by_level1(self, metrics: List[dict], level1: str) -> int:
        """
        ç»Ÿè®¡æŒ‡å®šä¸€çº§æŒ‡æ ‡ä¸‹çš„æŒ‡æ ‡æ•°é‡
        """
        return len([m for m in metrics if m.get('ä¸€çº§æŒ‡æ ‡') == level1])
    
