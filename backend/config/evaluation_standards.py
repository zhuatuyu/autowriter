#!/usr/bin/env python
"""
评价标准与类型（替代 YAML 配置，供 metric_evaluator_action 等使用）
"""

EVALUATION_TYPES = {
    "element_count": {
        "description": "根据各要素符合情况计分",
        "scoring_guidance": "1) 识别符合要素；2) 规则折算；3) 求和",
        "opinion_requirements": (
            "请按照以下格式撰写评价意见："
            "基于对项目资料的查阅和现场调研，本项目在以下方面表现如下："
            "① [要素名称]："
            "   评价结果：[满足/不满足]"
            "   具体事实：[引用具体文件、数据或现场发现，如'根据《XX文件》第X条规定'、'现场查看发现'、'查阅XX资料显示'等]"
            "   证据来源：[明确引用来源，如文件名称、文号、现场记录等]"
            "② [要素名称]："
            "   评价结果：[满足/不满足]"
            "   具体事实：[引用具体文件、数据或现场发现]"
            "   证据来源：[明确引用来源]"
            "③ [要素名称]："
            "   评价结果：[满足/不满足]"
            "   具体事实：[引用具体文件、数据或现场发现]"
            "   证据来源：[明确引用来源]"
            "综合评价：[基于上述事实，简要总结是否符合评价要点①②③等]"
        ),
    },
    "formula": {
        "description": "公式计算得分",
        "scoring_guidance": "1) 明确公式；2) 提取数据；3) 代入计算并换算到100分制",
        "opinion_requirements": (
            "请按照以下格式撰写评价意见："
            "基于对项目财务资料、合同文件等的查阅，评价结果如下："
            "① 计算公式：[明确写出计算公式及变量含义]"
            "② 数据来源：[列出每个变量的具体数值和来源，如'根据XX合同显示'、'查阅XX财务资料得知'等]"
            "③ 计算过程：[展示代入计算的具体过程，包含具体数字]"
            "④ 计算结果：[给出最终计算结果，如'资金到位率=42%']"
            "评价结论：[基于计算结果，说明是否符合评价要点要求]"
        ),
    },
    "condition": {
        "description": "条件判断计分",
        "scoring_guidance": "1) 匹配满足的档次；2) 取其对应分数",
        "opinion_requirements": (
            "请按照以下格式撰写评价意见："
            "基于对项目资料的全面查阅和现场调研，评价结果如下："
            "① [条件项名称]："
            "   评价结果：[满足/不满足]"
            "   具体事实：[引用具体文件、数据或现场发现，如'根据《XX文件》显示'、'现场查看发现'、'查阅XX资料得知'等]"
            "   证据来源：[明确引用来源，如文件名称、文号、现场记录等]"
            "② [条件项名称]："
            "   评价结果：[满足/不满足]"
            "   具体事实：[引用具体文件、数据或现场发现]"
            "   证据来源：[明确引用来源]"
            "③ [条件项名称]："
            "   评价结果：[满足/不满足]"
            "   具体事实：[引用具体文件、数据或现场发现]"
            "   证据来源：[明确引用来源]"
            "综合评价：[基于上述事实，简要总结是否符合评价要点①②③等]"
        ),
    },
    "qual_quant": {
        "description": "定性与定量结合",
        "scoring_guidance": "1) 分别计算定量与定性；2) 按权重合成",
        "opinion_requirements": (
            "请按照以下格式撰写评价意见："
            "基于对项目资料的查阅和现场调研，评价结果如下："
            "① 定量部分："
            "   数据来源：[具体说明数据来源，如'根据XX报告显示'、'查阅XX资料得知'等]"
            "   计算方法：[说明具体的计算方法]"
            "   计算结果：[给出具体的数值结果]"
            "② 定性部分："
            "   评价要点1：[要点名称] - [评价结果]"
            "   具体事实：[引用具体文件、数据或现场发现]"
            "   评价要点2：[要点名称] - [评价结果]"
            "   具体事实：[引用具体文件、数据或现场发现]"
            "③ 合成方式："
            "   权重分配：[说明权重与合成逻辑]"
            "   最终得分：[确保可复核]"
            "评价结论：[基于定量和定性分析，给出综合评价结果]"
        ),
    },
    "deduction": {
        "description": "递减扣分",
        "scoring_guidance": "1) 从满分开始；2) 按问题数量/严重度扣减",
        "opinion_requirements": (
            "请按照以下格式撰写评价意见："
            "基于对项目资料的查阅和现场调研，评价结果如下："
            "① 问题点1：[问题描述] - 扣分：[扣分值]"
            "   具体事实：[引用具体文件、数据或现场发现，如'根据XX资料显示'、'现场查看发现'、'查阅XX记录得知'等]"
            "   证据来源：[明确引用来源，如文件名称、文号、现场记录等]"
            "② 问题点2：[问题描述] - 扣分：[扣分值]"
            "   具体事实：[引用具体文件、数据或现场发现]"
            "   证据来源：[明确引用来源]"
            "③ 问题点3：[问题描述] - 扣分：[扣分值]"
            "   具体事实：[引用具体文件、数据或现场发现]"
            "   证据来源：[明确引用来源]"
            "扣分统计：累计扣分[总扣分值]，最终得分：[最终得分]"
            "评价结论：[基于扣分情况，说明项目在哪些方面存在问题]"
        ),
    },
    "likert": {
        "description": "李克特量表法",
        "scoring_guidance": "1) 按满意度百分比或档次映射得分",
        "opinion_requirements": (
            "请按照以下格式撰写评价意见："
            "基于对项目满意度调查的实施和数据分析，评价结果如下："
            "① 调查方法：[说明调查方法、样本量、抽样方式、回收率等具体信息]"
            "② 统计结果：[给出具体的统计数据和分布情况，包含具体数字]"
            "③ 数据质量：[说明样本代表性、潜在偏差及其影响]"
            "④ 得分映射：[根据满意度百分比或档次，明确对应的得分值，包含具体计算公式]"
            "评价结论：[基于调查结果，说明满意度水平及得分情况]"
            "确保评价过程透明可追溯，所有数据都有明确来源"
        ),
    },
}

SCORE_LEVELS = {
    "优秀": {"min": 90, "max": 100, "description": "项目实施非常成功，各项指标均达到或超过预期"},
    "良好": {"min": 80, "max": 89, "description": "项目实施比较成功，主要指标达到预期"},
    "一般": {"min": 70, "max": 79, "description": "项目基本完成，但部分指标有待改进"},
    "及格": {"min": 60, "max": 69, "description": "项目勉强完成，存在较多问题"},
    "较差": {"min": 0, "max": 59, "description": "项目实施效果不佳，需要重大改进"},
}

DIMENSION_WEIGHTS = {"决策": 20, "过程": 25, "产出": 30, "效益": 25}

LEVEL1_INDICATORS = ["决策", "过程", "产出", "效益"]

def GET_EVALUATION_LEVEL(total_score: float) -> str:
    for level, rng in SCORE_LEVELS.items():
        if rng["min"] <= total_score <= rng["max"]:
            return level
    return "未知"


